{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkpj2O0gFlB4"
      },
      "source": [
        "### Please run with Google Colab with Good GPU\n",
        "<a href=\"https://colab.research.google.com/github/Ichikawa-Satoshi/SI-Org-chart/blob/main/test_deeplearning/cross_valid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cUWebF5mFlB6",
        "outputId": "ea3d4857-caf2-472b-9626-d3cbc287a31f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "from sklearn.model_selection import KFold\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detectron2 has not released pre-built binaries for the latest pytorch (https://github.com/facebookresearch/detectron2/issues/4053)\n",
        "# so we install from source instead. This takes a few minutes.\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "BURJc3XNF1KU",
        "outputId": "d260dfc1-7d80-40a7-d317-3485ee34f200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "A UTF-8 locale is required. Got ANSI_X3.4-1968",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c1c849c0b2a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Detectron2 has not released pre-built binaries for the latest pytorch (https://github.com/facebookresearch/detectron2/issues/4053)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# so we install from source instead. This takes a few minutes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aMVlc2rLFlB7"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "i1DkNU4_FlB8",
        "outputId": "9aec527e-5d51-4842-9f75-3eaf1c2472bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 / 5\n",
            "[03/10 04:39:03 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [03/10 04:39:03 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:39:03 d2.data.datasets.coco]: Loaded 80 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train_fold0.json\n",
            "[03/10 04:39:03 d2.data.build]: Removed 0 images with no usable annotations. 80 images left.\n",
            "[03/10 04:39:03 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[03/10 04:39:03 d2.data.build]: Using training sampler TrainingSampler\n",
            "[03/10 04:39:03 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:39:03 d2.data.common]: Serializing 80 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:39:03 d2.data.common]: Serialized dataset takes 0.42 MiB\n",
            "[03/10 04:39:03 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [03/10 04:39:03 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[03/10 04:39:03 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/10 04:39:03 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[03/10 04:39:08 d2.utils.events]:  eta: 0:01:36  iter: 19  total_loss: 6.121  loss_cls: 1.104  loss_box_reg: 0.5136  loss_mask: 0.6966  loss_rpn_cls: 3.183  loss_rpn_loc: 0.4252    time: 0.2030  last_time: 0.1853  data_time: 0.0201  last_data_time: 0.0024   lr: 1.5585e-05  max_mem: 4336M\n",
            "[03/10 04:39:12 d2.utils.events]:  eta: 0:01:29  iter: 39  total_loss: 2.923  loss_cls: 0.912  loss_box_reg: 0.6584  loss_mask: 0.6433  loss_rpn_cls: 0.228  loss_rpn_loc: 0.2935    time: 0.2023  last_time: 0.1718  data_time: 0.0025  last_data_time: 0.0023   lr: 3.1569e-05  max_mem: 4336M\n",
            "[03/10 04:39:16 d2.utils.events]:  eta: 0:01:26  iter: 59  total_loss: 2.38  loss_cls: 0.7298  loss_box_reg: 0.6191  loss_mask: 0.5748  loss_rpn_cls: 0.1384  loss_rpn_loc: 0.2458    time: 0.2025  last_time: 0.1865  data_time: 0.0026  last_data_time: 0.0024   lr: 4.7553e-05  max_mem: 4336M\n",
            "[03/10 04:39:20 d2.utils.events]:  eta: 0:01:21  iter: 79  total_loss: 2.164  loss_cls: 0.6031  loss_box_reg: 0.7492  loss_mask: 0.4581  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.2056    time: 0.2008  last_time: 0.1853  data_time: 0.0024  last_data_time: 0.0022   lr: 6.3537e-05  max_mem: 4336M\n",
            "[03/10 04:39:24 d2.utils.events]:  eta: 0:01:18  iter: 99  total_loss: 1.849  loss_cls: 0.5186  loss_box_reg: 0.7015  loss_mask: 0.3886  loss_rpn_cls: 0.09171  loss_rpn_loc: 0.1908    time: 0.2008  last_time: 0.1856  data_time: 0.0025  last_data_time: 0.0028   lr: 7.9521e-05  max_mem: 4336M\n",
            "[03/10 04:39:28 d2.utils.events]:  eta: 0:01:14  iter: 119  total_loss: 1.861  loss_cls: 0.4796  loss_box_reg: 0.6922  loss_mask: 0.3545  loss_rpn_cls: 0.08876  loss_rpn_loc: 0.2089    time: 0.2011  last_time: 0.1981  data_time: 0.0025  last_data_time: 0.0025   lr: 9.5505e-05  max_mem: 4336M\n",
            "[03/10 04:39:32 d2.utils.events]:  eta: 0:01:10  iter: 139  total_loss: 1.684  loss_cls: 0.3827  loss_box_reg: 0.6586  loss_mask: 0.3307  loss_rpn_cls: 0.05474  loss_rpn_loc: 0.1859    time: 0.2003  last_time: 0.2345  data_time: 0.0025  last_data_time: 0.0028   lr: 0.00011149  max_mem: 4336M\n",
            "[03/10 04:39:36 d2.utils.events]:  eta: 0:01:06  iter: 159  total_loss: 1.517  loss_cls: 0.3435  loss_box_reg: 0.6327  loss_mask: 0.3173  loss_rpn_cls: 0.06141  loss_rpn_loc: 0.175    time: 0.2009  last_time: 0.1826  data_time: 0.0026  last_data_time: 0.0025   lr: 0.00012747  max_mem: 4336M\n",
            "[03/10 04:39:40 d2.utils.events]:  eta: 0:01:02  iter: 179  total_loss: 1.513  loss_cls: 0.3223  loss_box_reg: 0.6523  loss_mask: 0.2962  loss_rpn_cls: 0.04428  loss_rpn_loc: 0.1783    time: 0.2011  last_time: 0.2081  data_time: 0.0024  last_data_time: 0.0023   lr: 0.00014346  max_mem: 4336M\n",
            "[03/10 04:39:44 d2.utils.events]:  eta: 0:00:58  iter: 199  total_loss: 1.485  loss_cls: 0.3332  loss_box_reg: 0.6244  loss_mask: 0.2791  loss_rpn_cls: 0.04203  loss_rpn_loc: 0.1679    time: 0.2008  last_time: 0.1956  data_time: 0.0024  last_data_time: 0.0022   lr: 0.00015944  max_mem: 4336M\n",
            "[03/10 04:39:48 d2.utils.events]:  eta: 0:00:54  iter: 219  total_loss: 1.5  loss_cls: 0.3369  loss_box_reg: 0.6331  loss_mask: 0.2695  loss_rpn_cls: 0.06119  loss_rpn_loc: 0.1833    time: 0.2001  last_time: 0.1904  data_time: 0.0024  last_data_time: 0.0024   lr: 0.00017542  max_mem: 4336M\n",
            "[03/10 04:39:52 d2.utils.events]:  eta: 0:00:50  iter: 239  total_loss: 1.259  loss_cls: 0.2799  loss_box_reg: 0.5171  loss_mask: 0.2564  loss_rpn_cls: 0.04644  loss_rpn_loc: 0.1765    time: 0.2003  last_time: 0.1989  data_time: 0.0026  last_data_time: 0.0026   lr: 0.00019141  max_mem: 4336M\n",
            "[03/10 04:39:56 d2.utils.events]:  eta: 0:00:47  iter: 259  total_loss: 1.192  loss_cls: 0.2495  loss_box_reg: 0.5134  loss_mask: 0.2342  loss_rpn_cls: 0.03992  loss_rpn_loc: 0.1588    time: 0.2010  last_time: 0.1939  data_time: 0.0026  last_data_time: 0.0021   lr: 0.00020739  max_mem: 4336M\n",
            "[03/10 04:40:00 d2.utils.events]:  eta: 0:00:43  iter: 279  total_loss: 1.263  loss_cls: 0.2505  loss_box_reg: 0.5307  loss_mask: 0.2233  loss_rpn_cls: 0.04614  loss_rpn_loc: 0.1629    time: 0.2012  last_time: 0.2620  data_time: 0.0027  last_data_time: 0.0026   lr: 0.00022338  max_mem: 4336M\n",
            "[03/10 04:40:04 d2.utils.events]:  eta: 0:00:39  iter: 299  total_loss: 1.178  loss_cls: 0.2365  loss_box_reg: 0.53  loss_mask: 0.2243  loss_rpn_cls: 0.02611  loss_rpn_loc: 0.1862    time: 0.2012  last_time: 0.1908  data_time: 0.0026  last_data_time: 0.0023   lr: 0.00023936  max_mem: 4336M\n",
            "[03/10 04:40:08 d2.utils.events]:  eta: 0:00:35  iter: 319  total_loss: 1.033  loss_cls: 0.2177  loss_box_reg: 0.4453  loss_mask: 0.2156  loss_rpn_cls: 0.02622  loss_rpn_loc: 0.1499    time: 0.2012  last_time: 0.1771  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00025534  max_mem: 4336M\n",
            "[03/10 04:40:12 d2.utils.events]:  eta: 0:00:31  iter: 339  total_loss: 1.046  loss_cls: 0.2031  loss_box_reg: 0.4962  loss_mask: 0.2147  loss_rpn_cls: 0.02012  loss_rpn_loc: 0.1624    time: 0.2012  last_time: 0.1931  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00027133  max_mem: 4336M\n",
            "[03/10 04:40:16 d2.utils.events]:  eta: 0:00:27  iter: 359  total_loss: 1.111  loss_cls: 0.2191  loss_box_reg: 0.4737  loss_mask: 0.2147  loss_rpn_cls: 0.02807  loss_rpn_loc: 0.1812    time: 0.2017  last_time: 0.1908  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00028731  max_mem: 4336M\n",
            "[03/10 04:40:20 d2.utils.events]:  eta: 0:00:23  iter: 379  total_loss: 0.973  loss_cls: 0.1894  loss_box_reg: 0.4358  loss_mask: 0.1992  loss_rpn_cls: 0.03647  loss_rpn_loc: 0.1601    time: 0.2016  last_time: 0.2362  data_time: 0.0025  last_data_time: 0.0024   lr: 0.0003033  max_mem: 4336M\n",
            "[03/10 04:40:24 d2.utils.events]:  eta: 0:00:19  iter: 399  total_loss: 1.032  loss_cls: 0.1863  loss_box_reg: 0.4331  loss_mask: 0.1853  loss_rpn_cls: 0.02637  loss_rpn_loc: 0.1792    time: 0.2015  last_time: 0.1816  data_time: 0.0026  last_data_time: 0.0023   lr: 0.00031928  max_mem: 4336M\n",
            "[03/10 04:40:29 d2.utils.events]:  eta: 0:00:15  iter: 419  total_loss: 0.9361  loss_cls: 0.1655  loss_box_reg: 0.3587  loss_mask: 0.178  loss_rpn_cls: 0.02249  loss_rpn_loc: 0.1573    time: 0.2018  last_time: 0.2124  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00033526  max_mem: 4336M\n",
            "[03/10 04:40:33 d2.utils.events]:  eta: 0:00:11  iter: 439  total_loss: 0.9858  loss_cls: 0.1918  loss_box_reg: 0.3664  loss_mask: 0.183  loss_rpn_cls: 0.01807  loss_rpn_loc: 0.1678    time: 0.2020  last_time: 0.2311  data_time: 0.0026  last_data_time: 0.0024   lr: 0.00035125  max_mem: 4336M\n",
            "[03/10 04:40:37 d2.utils.events]:  eta: 0:00:07  iter: 459  total_loss: 0.9619  loss_cls: 0.2086  loss_box_reg: 0.4295  loss_mask: 0.1809  loss_rpn_cls: 0.02085  loss_rpn_loc: 0.1779    time: 0.2022  last_time: 0.2198  data_time: 0.0027  last_data_time: 0.0027   lr: 0.00036723  max_mem: 4336M\n",
            "[03/10 04:40:41 d2.utils.events]:  eta: 0:00:03  iter: 479  total_loss: 0.9603  loss_cls: 0.1957  loss_box_reg: 0.3585  loss_mask: 0.1836  loss_rpn_cls: 0.02025  loss_rpn_loc: 0.1369    time: 0.2020  last_time: 0.2364  data_time: 0.0026  last_data_time: 0.0025   lr: 0.00038322  max_mem: 4336M\n",
            "[03/10 04:40:46 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.8817  loss_cls: 0.1785  loss_box_reg: 0.3406  loss_mask: 0.1874  loss_rpn_cls: 0.0173  loss_rpn_loc: 0.1583    time: 0.2019  last_time: 0.1900  data_time: 0.0025  last_data_time: 0.0024   lr: 0.0003992  max_mem: 4336M\n",
            "[03/10 04:40:47 d2.engine.hooks]: Overall training speed: 498 iterations in 0:01:40 (0.2020 s / it)\n",
            "[03/10 04:40:47 d2.engine.hooks]: Total training time: 0:01:42 (0:00:01 on hooks)\n",
            "WARNING [03/10 04:40:47 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:40:47 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold0.json\n",
            "[03/10 04:40:47 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:40:47 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:40:47 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:40:47 d2.data.common]: Serialized dataset takes 0.10 MiB\n",
            "WARNING [03/10 04:40:47 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "WARNING [03/10 04:40:47 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "WARNING [03/10 04:40:47 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:40:47 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold0.json\n",
            "[03/10 04:40:47 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:40:47 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:40:47 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:40:47 d2.data.common]: Serialized dataset takes 0.10 MiB\n",
            "[03/10 04:40:47 d2.evaluation.evaluator]: Start inference on 20 batches\n",
            "[03/10 04:40:53 d2.evaluation.evaluator]: Inference done 11/20. Dataloading: 0.0012 s/iter. Inference: 0.1244 s/iter. Eval: 0.2630 s/iter. Total: 0.3886 s/iter. ETA=0:00:03\n",
            "[03/10 04:40:58 d2.evaluation.evaluator]: Inference done 17/20. Dataloading: 0.0014 s/iter. Inference: 0.1548 s/iter. Eval: 0.4618 s/iter. Total: 0.6182 s/iter. ETA=0:00:01\n",
            "[03/10 04:41:01 d2.evaluation.evaluator]: Total inference time: 0:00:10.161275 (0.677418 s / iter per device, on 1 devices)\n",
            "[03/10 04:41:01 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.163033 s / iter per device, on 1 devices)\n",
            "[03/10 04:41:01 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[03/10 04:41:01 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n",
            "[03/10 04:41:01 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:41:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[03/10 04:41:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n",
            "[03/10 04:41:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:41:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.924\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.760\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.636\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.432\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            "[03/10 04:41:01 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 60.686 | 92.444 | 76.016 |  nan  | 53.034 | 63.618 |\n",
            "[03/10 04:41:01 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:41:01 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 54.776 | info       | 66.596 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:41:01 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[03/10 04:41:01 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.\n",
            "[03/10 04:41:01 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:41:01 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.924\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.759\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.549\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.649\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.677\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.698\n",
            "[03/10 04:41:01 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 61.956 | 92.429 | 75.938 |  nan  | 54.909 | 64.873 |\n",
            "[03/10 04:41:01 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:41:01 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 56.693 | info       | 67.219 |\n",
            "Fold 1: AP=60.69, AP50=92.44, AP75=76.02\n",
            "Fold 2 / 5\n",
            "[03/10 04:41:02 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [03/10 04:41:02 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:41:02 d2.data.datasets.coco]: Loaded 80 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train_fold1.json\n",
            "[03/10 04:41:02 d2.data.build]: Removed 0 images with no usable annotations. 80 images left.\n",
            "[03/10 04:41:02 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[03/10 04:41:02 d2.data.build]: Using training sampler TrainingSampler\n",
            "[03/10 04:41:02 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:41:02 d2.data.common]: Serializing 80 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:41:02 d2.data.common]: Serialized dataset takes 0.40 MiB\n",
            "[03/10 04:41:02 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [03/10 04:41:02 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[03/10 04:41:02 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/10 04:41:02 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[03/10 04:41:07 d2.utils.events]:  eta: 0:01:42  iter: 19  total_loss: 6.174  loss_cls: 1.102  loss_box_reg: 0.5826  loss_mask: 0.697  loss_rpn_cls: 3.484  loss_rpn_loc: 0.4113    time: 0.2093  last_time: 0.2359  data_time: 0.0207  last_data_time: 0.0025   lr: 1.5585e-05  max_mem: 5817M\n",
            "[03/10 04:41:11 d2.utils.events]:  eta: 0:01:34  iter: 39  total_loss: 2.766  loss_cls: 0.8916  loss_box_reg: 0.6568  loss_mask: 0.6452  loss_rpn_cls: 0.2249  loss_rpn_loc: 0.3206    time: 0.2058  last_time: 0.1838  data_time: 0.0025  last_data_time: 0.0026   lr: 3.1569e-05  max_mem: 5817M\n",
            "[03/10 04:41:15 d2.utils.events]:  eta: 0:01:29  iter: 59  total_loss: 2.293  loss_cls: 0.6973  loss_box_reg: 0.6964  loss_mask: 0.5606  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.2106    time: 0.2043  last_time: 0.2221  data_time: 0.0025  last_data_time: 0.0027   lr: 4.7553e-05  max_mem: 5817M\n",
            "[03/10 04:41:19 d2.utils.events]:  eta: 0:01:24  iter: 79  total_loss: 2.063  loss_cls: 0.5866  loss_box_reg: 0.7047  loss_mask: 0.4639  loss_rpn_cls: 0.07536  loss_rpn_loc: 0.1907    time: 0.2033  last_time: 0.1887  data_time: 0.0026  last_data_time: 0.0023   lr: 6.3537e-05  max_mem: 5817M\n",
            "[03/10 04:41:23 d2.utils.events]:  eta: 0:01:21  iter: 99  total_loss: 1.971  loss_cls: 0.5174  loss_box_reg: 0.7297  loss_mask: 0.3963  loss_rpn_cls: 0.09761  loss_rpn_loc: 0.1824    time: 0.2046  last_time: 0.1965  data_time: 0.0026  last_data_time: 0.0027   lr: 7.9521e-05  max_mem: 5817M\n",
            "[03/10 04:41:27 d2.utils.events]:  eta: 0:01:17  iter: 119  total_loss: 1.769  loss_cls: 0.4524  loss_box_reg: 0.6302  loss_mask: 0.3588  loss_rpn_cls: 0.07934  loss_rpn_loc: 0.1748    time: 0.2049  last_time: 0.1692  data_time: 0.0024  last_data_time: 0.0026   lr: 9.5505e-05  max_mem: 5817M\n",
            "[03/10 04:41:32 d2.utils.events]:  eta: 0:01:12  iter: 139  total_loss: 1.715  loss_cls: 0.3844  loss_box_reg: 0.6784  loss_mask: 0.3313  loss_rpn_cls: 0.06388  loss_rpn_loc: 0.1742    time: 0.2044  last_time: 0.2251  data_time: 0.0024  last_data_time: 0.0024   lr: 0.00011149  max_mem: 5817M\n",
            "[03/10 04:41:35 d2.utils.events]:  eta: 0:01:08  iter: 159  total_loss: 1.467  loss_cls: 0.3249  loss_box_reg: 0.5807  loss_mask: 0.3273  loss_rpn_cls: 0.06575  loss_rpn_loc: 0.1648    time: 0.2036  last_time: 0.1656  data_time: 0.0024  last_data_time: 0.0025   lr: 0.00012747  max_mem: 5817M\n",
            "[03/10 04:41:40 d2.utils.events]:  eta: 0:01:04  iter: 179  total_loss: 1.494  loss_cls: 0.3179  loss_box_reg: 0.6526  loss_mask: 0.2858  loss_rpn_cls: 0.07524  loss_rpn_loc: 0.1671    time: 0.2043  last_time: 0.1853  data_time: 0.0026  last_data_time: 0.0029   lr: 0.00014346  max_mem: 5817M\n",
            "[03/10 04:41:44 d2.utils.events]:  eta: 0:01:00  iter: 199  total_loss: 1.442  loss_cls: 0.3074  loss_box_reg: 0.5986  loss_mask: 0.2992  loss_rpn_cls: 0.03628  loss_rpn_loc: 0.1708    time: 0.2037  last_time: 0.1861  data_time: 0.0026  last_data_time: 0.0024   lr: 0.00015944  max_mem: 5817M\n",
            "[03/10 04:41:48 d2.utils.events]:  eta: 0:00:56  iter: 219  total_loss: 1.268  loss_cls: 0.2648  loss_box_reg: 0.571  loss_mask: 0.2522  loss_rpn_cls: 0.04117  loss_rpn_loc: 0.147    time: 0.2035  last_time: 0.2004  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00017542  max_mem: 5817M\n",
            "[03/10 04:41:52 d2.utils.events]:  eta: 0:00:52  iter: 239  total_loss: 1.274  loss_cls: 0.2832  loss_box_reg: 0.5579  loss_mask: 0.2508  loss_rpn_cls: 0.03298  loss_rpn_loc: 0.1634    time: 0.2038  last_time: 0.1940  data_time: 0.0026  last_data_time: 0.0026   lr: 0.00019141  max_mem: 5817M\n",
            "[03/10 04:41:56 d2.utils.events]:  eta: 0:00:47  iter: 259  total_loss: 1.33  loss_cls: 0.2684  loss_box_reg: 0.5504  loss_mask: 0.2509  loss_rpn_cls: 0.05033  loss_rpn_loc: 0.1971    time: 0.2030  last_time: 0.1738  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00020739  max_mem: 5817M\n",
            "[03/10 04:42:00 d2.utils.events]:  eta: 0:00:43  iter: 279  total_loss: 1.091  loss_cls: 0.2664  loss_box_reg: 0.5  loss_mask: 0.2216  loss_rpn_cls: 0.02955  loss_rpn_loc: 0.1443    time: 0.2028  last_time: 0.1932  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00022338  max_mem: 5817M\n",
            "[03/10 04:42:04 d2.utils.events]:  eta: 0:00:39  iter: 299  total_loss: 1.26  loss_cls: 0.2526  loss_box_reg: 0.5171  loss_mask: 0.2465  loss_rpn_cls: 0.03866  loss_rpn_loc: 0.1658    time: 0.2026  last_time: 0.1704  data_time: 0.0025  last_data_time: 0.0023   lr: 0.00023936  max_mem: 5817M\n",
            "[03/10 04:42:08 d2.utils.events]:  eta: 0:00:36  iter: 319  total_loss: 1.084  loss_cls: 0.2157  loss_box_reg: 0.4607  loss_mask: 0.2019  loss_rpn_cls: 0.02683  loss_rpn_loc: 0.1471    time: 0.2024  last_time: 0.1896  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00025534  max_mem: 5817M\n",
            "[03/10 04:42:12 d2.utils.events]:  eta: 0:00:31  iter: 339  total_loss: 1.15  loss_cls: 0.2363  loss_box_reg: 0.4459  loss_mask: 0.2069  loss_rpn_cls: 0.03057  loss_rpn_loc: 0.2078    time: 0.2020  last_time: 0.1853  data_time: 0.0024  last_data_time: 0.0022   lr: 0.00027133  max_mem: 5817M\n",
            "[03/10 04:42:16 d2.utils.events]:  eta: 0:00:27  iter: 359  total_loss: 1.065  loss_cls: 0.2079  loss_box_reg: 0.4237  loss_mask: 0.192  loss_rpn_cls: 0.02115  loss_rpn_loc: 0.1651    time: 0.2015  last_time: 0.1825  data_time: 0.0030  last_data_time: 0.0030   lr: 0.00028731  max_mem: 5817M\n",
            "[03/10 04:42:19 d2.utils.events]:  eta: 0:00:23  iter: 379  total_loss: 1.059  loss_cls: 0.2652  loss_box_reg: 0.4561  loss_mask: 0.1871  loss_rpn_cls: 0.02586  loss_rpn_loc: 0.162    time: 0.2007  last_time: 0.2181  data_time: 0.0023  last_data_time: 0.0024   lr: 0.0003033  max_mem: 5817M\n",
            "[03/10 04:42:23 d2.utils.events]:  eta: 0:00:19  iter: 399  total_loss: 1.027  loss_cls: 0.2041  loss_box_reg: 0.4203  loss_mask: 0.1953  loss_rpn_cls: 0.03337  loss_rpn_loc: 0.1661    time: 0.2007  last_time: 0.1863  data_time: 0.0024  last_data_time: 0.0025   lr: 0.00031928  max_mem: 5817M\n",
            "[03/10 04:42:27 d2.utils.events]:  eta: 0:00:15  iter: 419  total_loss: 1.101  loss_cls: 0.2364  loss_box_reg: 0.4299  loss_mask: 0.1969  loss_rpn_cls: 0.03941  loss_rpn_loc: 0.188    time: 0.2007  last_time: 0.2174  data_time: 0.0026  last_data_time: 0.0031   lr: 0.00033526  max_mem: 5817M\n",
            "[03/10 04:42:31 d2.utils.events]:  eta: 0:00:11  iter: 439  total_loss: 0.8597  loss_cls: 0.1672  loss_box_reg: 0.3207  loss_mask: 0.1867  loss_rpn_cls: 0.02458  loss_rpn_loc: 0.1513    time: 0.2009  last_time: 0.2171  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00035125  max_mem: 5817M\n",
            "[03/10 04:42:35 d2.utils.events]:  eta: 0:00:07  iter: 459  total_loss: 0.9089  loss_cls: 0.1693  loss_box_reg: 0.3948  loss_mask: 0.177  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.1685    time: 0.2006  last_time: 0.1865  data_time: 0.0025  last_data_time: 0.0028   lr: 0.00036723  max_mem: 5817M\n",
            "[03/10 04:42:39 d2.utils.events]:  eta: 0:00:03  iter: 479  total_loss: 0.8154  loss_cls: 0.153  loss_box_reg: 0.3247  loss_mask: 0.1726  loss_rpn_cls: 0.01698  loss_rpn_loc: 0.1453    time: 0.2009  last_time: 0.2316  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00038322  max_mem: 5817M\n",
            "[03/10 04:42:44 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.8789  loss_cls: 0.17  loss_box_reg: 0.3217  loss_mask: 0.1736  loss_rpn_cls: 0.02492  loss_rpn_loc: 0.1834    time: 0.2009  last_time: 0.1700  data_time: 0.0025  last_data_time: 0.0025   lr: 0.0003992  max_mem: 5817M\n",
            "[03/10 04:42:45 d2.engine.hooks]: Overall training speed: 498 iterations in 0:01:40 (0.2009 s / it)\n",
            "[03/10 04:42:45 d2.engine.hooks]: Total training time: 0:01:41 (0:00:01 on hooks)\n",
            "WARNING [03/10 04:42:45 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:42:45 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold1.json\n",
            "[03/10 04:42:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:42:45 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:42:45 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:42:45 d2.data.common]: Serialized dataset takes 0.12 MiB\n",
            "WARNING [03/10 04:42:45 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "WARNING [03/10 04:42:45 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "WARNING [03/10 04:42:45 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:42:45 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold1.json\n",
            "[03/10 04:42:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:42:45 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:42:45 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:42:45 d2.data.common]: Serialized dataset takes 0.12 MiB\n",
            "[03/10 04:42:45 d2.evaluation.evaluator]: Start inference on 20 batches\n",
            "[03/10 04:42:51 d2.evaluation.evaluator]: Inference done 11/20. Dataloading: 0.0012 s/iter. Inference: 0.1248 s/iter. Eval: 0.2392 s/iter. Total: 0.3652 s/iter. ETA=0:00:03\n",
            "[03/10 04:42:57 d2.evaluation.evaluator]: Inference done 17/20. Dataloading: 0.0014 s/iter. Inference: 0.1610 s/iter. Eval: 0.4782 s/iter. Total: 0.6408 s/iter. ETA=0:00:01\n",
            "[03/10 04:42:59 d2.evaluation.evaluator]: Total inference time: 0:00:10.325804 (0.688387 s / iter per device, on 1 devices)\n",
            "[03/10 04:42:59 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.166099 s / iter per device, on 1 devices)\n",
            "[03/10 04:42:59 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[03/10 04:42:59 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n",
            "[03/10 04:43:00 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:43:00 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[03/10 04:43:00 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.\n",
            "[03/10 04:43:00 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:43:00 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.616\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.924\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.718\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.628\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.158\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.474\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.698\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.580\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712\n",
            "[03/10 04:43:00 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 61.635 | 92.365 | 71.811 | 5.000 | 50.189 | 62.811 |\n",
            "[03/10 04:43:00 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 49.564 | info       | 73.707 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:43:00 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[03/10 04:43:00 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.\n",
            "[03/10 04:43:00 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:43:00 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.621\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.925\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.710\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.594\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            "[03/10 04:43:00 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 62.092 | 92.455 | 71.012 | 5.000 | 50.043 | 62.864 |\n",
            "[03/10 04:43:00 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 49.395 | info       | 74.790 |\n",
            "Fold 2: AP=61.64, AP50=92.36, AP75=71.81\n",
            "Fold 3 / 5\n",
            "[03/10 04:43:00 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [03/10 04:43:00 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:43:00 d2.data.datasets.coco]: Loaded 80 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train_fold2.json\n",
            "[03/10 04:43:00 d2.data.build]: Removed 0 images with no usable annotations. 80 images left.\n",
            "[03/10 04:43:00 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[03/10 04:43:00 d2.data.build]: Using training sampler TrainingSampler\n",
            "[03/10 04:43:00 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:43:01 d2.data.common]: Serializing 80 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:43:01 d2.data.common]: Serialized dataset takes 0.44 MiB\n",
            "[03/10 04:43:01 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [03/10 04:43:01 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[03/10 04:43:01 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/10 04:43:01 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[03/10 04:43:05 d2.utils.events]:  eta: 0:01:32  iter: 19  total_loss: 6.296  loss_cls: 1.266  loss_box_reg: 0.5807  loss_mask: 0.6971  loss_rpn_cls: 3.362  loss_rpn_loc: 0.3538    time: 0.1967  last_time: 0.1485  data_time: 0.0192  last_data_time: 0.0031   lr: 1.5585e-05  max_mem: 5817M\n",
            "[03/10 04:43:09 d2.utils.events]:  eta: 0:01:30  iter: 39  total_loss: 3.004  loss_cls: 0.9651  loss_box_reg: 0.7083  loss_mask: 0.6533  loss_rpn_cls: 0.3282  loss_rpn_loc: 0.3104    time: 0.1986  last_time: 0.1937  data_time: 0.0027  last_data_time: 0.0025   lr: 3.1569e-05  max_mem: 5817M\n",
            "[03/10 04:43:13 d2.utils.events]:  eta: 0:01:26  iter: 59  total_loss: 2.257  loss_cls: 0.7095  loss_box_reg: 0.6477  loss_mask: 0.5792  loss_rpn_cls: 0.1232  loss_rpn_loc: 0.2163    time: 0.2009  last_time: 0.1781  data_time: 0.0027  last_data_time: 0.0024   lr: 4.7553e-05  max_mem: 5817M\n",
            "[03/10 04:43:17 d2.utils.events]:  eta: 0:01:23  iter: 79  total_loss: 2.178  loss_cls: 0.5636  loss_box_reg: 0.7168  loss_mask: 0.4712  loss_rpn_cls: 0.07205  loss_rpn_loc: 0.2466    time: 0.2024  last_time: 0.1984  data_time: 0.0026  last_data_time: 0.0027   lr: 6.3537e-05  max_mem: 5817M\n",
            "[03/10 04:43:21 d2.utils.events]:  eta: 0:01:18  iter: 99  total_loss: 1.893  loss_cls: 0.4837  loss_box_reg: 0.7248  loss_mask: 0.4089  loss_rpn_cls: 0.05953  loss_rpn_loc: 0.1928    time: 0.2017  last_time: 0.2216  data_time: 0.0025  last_data_time: 0.0026   lr: 7.9521e-05  max_mem: 5817M\n",
            "[03/10 04:43:25 d2.utils.events]:  eta: 0:01:15  iter: 119  total_loss: 1.775  loss_cls: 0.4339  loss_box_reg: 0.6562  loss_mask: 0.3431  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.2245    time: 0.2021  last_time: 0.1642  data_time: 0.0024  last_data_time: 0.0023   lr: 9.5505e-05  max_mem: 5817M\n",
            "[03/10 04:43:30 d2.utils.events]:  eta: 0:01:11  iter: 139  total_loss: 1.65  loss_cls: 0.3714  loss_box_reg: 0.6648  loss_mask: 0.3218  loss_rpn_cls: 0.06413  loss_rpn_loc: 0.1797    time: 0.2019  last_time: 0.2011  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00011149  max_mem: 5817M\n",
            "[03/10 04:43:34 d2.utils.events]:  eta: 0:01:07  iter: 159  total_loss: 1.487  loss_cls: 0.3208  loss_box_reg: 0.606  loss_mask: 0.3357  loss_rpn_cls: 0.05658  loss_rpn_loc: 0.1478    time: 0.2034  last_time: 0.2466  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00012747  max_mem: 5817M\n",
            "[03/10 04:43:38 d2.utils.events]:  eta: 0:01:04  iter: 179  total_loss: 1.509  loss_cls: 0.3108  loss_box_reg: 0.6569  loss_mask: 0.308  loss_rpn_cls: 0.05433  loss_rpn_loc: 0.1507    time: 0.2036  last_time: 0.1626  data_time: 0.0024  last_data_time: 0.0023   lr: 0.00014346  max_mem: 5817M\n",
            "[03/10 04:43:42 d2.utils.events]:  eta: 0:01:00  iter: 199  total_loss: 1.446  loss_cls: 0.2944  loss_box_reg: 0.6161  loss_mask: 0.3038  loss_rpn_cls: 0.04893  loss_rpn_loc: 0.1767    time: 0.2034  last_time: 0.1768  data_time: 0.0026  last_data_time: 0.0025   lr: 0.00015944  max_mem: 5817M\n",
            "[03/10 04:43:46 d2.utils.events]:  eta: 0:00:56  iter: 219  total_loss: 1.325  loss_cls: 0.2587  loss_box_reg: 0.565  loss_mask: 0.2737  loss_rpn_cls: 0.05187  loss_rpn_loc: 0.1845    time: 0.2036  last_time: 0.2131  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00017542  max_mem: 5817M\n",
            "[03/10 04:43:50 d2.utils.events]:  eta: 0:00:52  iter: 239  total_loss: 1.258  loss_cls: 0.2616  loss_box_reg: 0.546  loss_mask: 0.2596  loss_rpn_cls: 0.03412  loss_rpn_loc: 0.1656    time: 0.2036  last_time: 0.1945  data_time: 0.0026  last_data_time: 0.0026   lr: 0.00019141  max_mem: 5817M\n",
            "[03/10 04:43:54 d2.utils.events]:  eta: 0:00:48  iter: 259  total_loss: 1.288  loss_cls: 0.2707  loss_box_reg: 0.551  loss_mask: 0.2523  loss_rpn_cls: 0.03442  loss_rpn_loc: 0.1692    time: 0.2031  last_time: 0.2074  data_time: 0.0026  last_data_time: 0.0023   lr: 0.00020739  max_mem: 5817M\n",
            "[03/10 04:43:58 d2.utils.events]:  eta: 0:00:44  iter: 279  total_loss: 1.173  loss_cls: 0.2273  loss_box_reg: 0.5039  loss_mask: 0.2274  loss_rpn_cls: 0.03008  loss_rpn_loc: 0.1513    time: 0.2032  last_time: 0.2243  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00022338  max_mem: 5817M\n",
            "[03/10 04:44:02 d2.utils.events]:  eta: 0:00:39  iter: 299  total_loss: 1.132  loss_cls: 0.2345  loss_box_reg: 0.4526  loss_mask: 0.2162  loss_rpn_cls: 0.03763  loss_rpn_loc: 0.167    time: 0.2024  last_time: 0.1809  data_time: 0.0024  last_data_time: 0.0027   lr: 0.00023936  max_mem: 5817M\n",
            "[03/10 04:44:06 d2.utils.events]:  eta: 0:00:36  iter: 319  total_loss: 0.9964  loss_cls: 0.2085  loss_box_reg: 0.4504  loss_mask: 0.1888  loss_rpn_cls: 0.02368  loss_rpn_loc: 0.1437    time: 0.2028  last_time: 0.2155  data_time: 0.0025  last_data_time: 0.0023   lr: 0.00025534  max_mem: 5817M\n",
            "[03/10 04:44:10 d2.utils.events]:  eta: 0:00:31  iter: 339  total_loss: 1.051  loss_cls: 0.2244  loss_box_reg: 0.4629  loss_mask: 0.1899  loss_rpn_cls: 0.0277  loss_rpn_loc: 0.17    time: 0.2028  last_time: 0.1780  data_time: 0.0026  last_data_time: 0.0026   lr: 0.00027133  max_mem: 5817M\n",
            "[03/10 04:44:14 d2.utils.events]:  eta: 0:00:28  iter: 359  total_loss: 1.181  loss_cls: 0.2331  loss_box_reg: 0.4865  loss_mask: 0.2106  loss_rpn_cls: 0.02539  loss_rpn_loc: 0.213    time: 0.2028  last_time: 0.1826  data_time: 0.0026  last_data_time: 0.0029   lr: 0.00028731  max_mem: 5817M\n",
            "[03/10 04:44:18 d2.utils.events]:  eta: 0:00:24  iter: 379  total_loss: 1.047  loss_cls: 0.205  loss_box_reg: 0.4276  loss_mask: 0.2054  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.171    time: 0.2029  last_time: 0.1704  data_time: 0.0025  last_data_time: 0.0022   lr: 0.0003033  max_mem: 5817M\n",
            "[03/10 04:44:22 d2.utils.events]:  eta: 0:00:20  iter: 399  total_loss: 1.025  loss_cls: 0.1948  loss_box_reg: 0.4257  loss_mask: 0.1981  loss_rpn_cls: 0.01685  loss_rpn_loc: 0.169    time: 0.2026  last_time: 0.2176  data_time: 0.0027  last_data_time: 0.0025   lr: 0.00031928  max_mem: 5817M\n",
            "[03/10 04:44:27 d2.utils.events]:  eta: 0:00:15  iter: 419  total_loss: 1.07  loss_cls: 0.2035  loss_box_reg: 0.4096  loss_mask: 0.2035  loss_rpn_cls: 0.02257  loss_rpn_loc: 0.1803    time: 0.2028  last_time: 0.1992  data_time: 0.0025  last_data_time: 0.0022   lr: 0.00033526  max_mem: 5817M\n",
            "[03/10 04:44:31 d2.utils.events]:  eta: 0:00:12  iter: 439  total_loss: 0.8638  loss_cls: 0.152  loss_box_reg: 0.3203  loss_mask: 0.1725  loss_rpn_cls: 0.02282  loss_rpn_loc: 0.1752    time: 0.2028  last_time: 0.2152  data_time: 0.0026  last_data_time: 0.0025   lr: 0.00035125  max_mem: 5817M\n",
            "[03/10 04:44:35 d2.utils.events]:  eta: 0:00:08  iter: 459  total_loss: 0.9765  loss_cls: 0.2019  loss_box_reg: 0.3896  loss_mask: 0.174  loss_rpn_cls: 0.02109  loss_rpn_loc: 0.1603    time: 0.2031  last_time: 0.1770  data_time: 0.0024  last_data_time: 0.0023   lr: 0.00036723  max_mem: 5817M\n",
            "[03/10 04:44:39 d2.utils.events]:  eta: 0:00:04  iter: 479  total_loss: 0.7872  loss_cls: 0.1597  loss_box_reg: 0.3298  loss_mask: 0.1665  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.1448    time: 0.2028  last_time: 0.2020  data_time: 0.0026  last_data_time: 0.0026   lr: 0.00038322  max_mem: 5817M\n",
            "[03/10 04:44:44 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.9182  loss_cls: 0.1952  loss_box_reg: 0.3477  loss_mask: 0.1714  loss_rpn_cls: 0.02132  loss_rpn_loc: 0.1323    time: 0.2030  last_time: 0.1767  data_time: 0.0026  last_data_time: 0.0026   lr: 0.0003992  max_mem: 5817M\n",
            "[03/10 04:44:45 d2.engine.hooks]: Overall training speed: 498 iterations in 0:01:41 (0.2030 s / it)\n",
            "[03/10 04:44:45 d2.engine.hooks]: Total training time: 0:01:43 (0:00:01 on hooks)\n",
            "WARNING [03/10 04:44:45 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:44:45 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold2.json\n",
            "[03/10 04:44:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:44:45 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:44:45 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:44:45 d2.data.common]: Serialized dataset takes 0.08 MiB\n",
            "WARNING [03/10 04:44:45 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "WARNING [03/10 04:44:45 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "WARNING [03/10 04:44:45 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:44:45 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold2.json\n",
            "[03/10 04:44:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:44:45 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:44:45 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:44:45 d2.data.common]: Serialized dataset takes 0.08 MiB\n",
            "[03/10 04:44:45 d2.evaluation.evaluator]: Start inference on 20 batches\n",
            "[03/10 04:44:51 d2.evaluation.evaluator]: Inference done 11/20. Dataloading: 0.0014 s/iter. Inference: 0.1348 s/iter. Eval: 0.2805 s/iter. Total: 0.4167 s/iter. ETA=0:00:03\n",
            "[03/10 04:44:56 d2.evaluation.evaluator]: Inference done 19/20. Dataloading: 0.0014 s/iter. Inference: 0.1495 s/iter. Eval: 0.3938 s/iter. Total: 0.5449 s/iter. ETA=0:00:00\n",
            "[03/10 04:44:57 d2.evaluation.evaluator]: Total inference time: 0:00:08.451705 (0.563447 s / iter per device, on 1 devices)\n",
            "[03/10 04:44:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.151279 s / iter per device, on 1 devices)\n",
            "[03/10 04:44:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[03/10 04:44:57 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n",
            "[03/10 04:44:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:44:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[03/10 04:44:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n",
            "[03/10 04:44:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:44:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.581\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.893\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.686\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.453\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.669\n",
            "[03/10 04:44:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 58.100 | 89.291 | 68.644 |  nan  | 40.713 | 60.844 |\n",
            "[03/10 04:44:57 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:44:57 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 46.685 | info       | 69.515 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:44:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[03/10 04:44:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.\n",
            "[03/10 04:44:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:44:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.592\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.892\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.674\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.615\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.139\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.662\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673\n",
            "[03/10 04:44:57 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 59.194 | 89.241 | 67.442 |  nan  | 41.702 | 61.464 |\n",
            "[03/10 04:44:57 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:44:57 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 46.738 | info       | 71.650 |\n",
            "Fold 3: AP=58.10, AP50=89.29, AP75=68.64\n",
            "Fold 4 / 5\n",
            "[03/10 04:44:58 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [03/10 04:44:58 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:44:58 d2.data.datasets.coco]: Loaded 80 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train_fold3.json\n",
            "[03/10 04:44:58 d2.data.build]: Removed 0 images with no usable annotations. 80 images left.\n",
            "[03/10 04:44:58 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[03/10 04:44:58 d2.data.build]: Using training sampler TrainingSampler\n",
            "[03/10 04:44:58 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:44:58 d2.data.common]: Serializing 80 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:44:58 d2.data.common]: Serialized dataset takes 0.41 MiB\n",
            "[03/10 04:44:58 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [03/10 04:44:58 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[03/10 04:44:58 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/10 04:44:58 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[03/10 04:45:03 d2.utils.events]:  eta: 0:01:33  iter: 19  total_loss: 5.609  loss_cls: 0.9219  loss_box_reg: 0.5159  loss_mask: 0.6798  loss_rpn_cls: 3.108  loss_rpn_loc: 0.4228    time: 0.1998  last_time: 0.2180  data_time: 0.0196  last_data_time: 0.0022   lr: 1.5585e-05  max_mem: 5817M\n",
            "[03/10 04:45:07 d2.utils.events]:  eta: 0:01:30  iter: 39  total_loss: 2.773  loss_cls: 0.8464  loss_box_reg: 0.7041  loss_mask: 0.6425  loss_rpn_cls: 0.2341  loss_rpn_loc: 0.3187    time: 0.1984  last_time: 0.2163  data_time: 0.0027  last_data_time: 0.0027   lr: 3.1569e-05  max_mem: 5817M\n",
            "[03/10 04:45:11 d2.utils.events]:  eta: 0:01:27  iter: 59  total_loss: 2.439  loss_cls: 0.6947  loss_box_reg: 0.6782  loss_mask: 0.5646  loss_rpn_cls: 0.1435  loss_rpn_loc: 0.2793    time: 0.1999  last_time: 0.2271  data_time: 0.0025  last_data_time: 0.0025   lr: 4.7553e-05  max_mem: 5817M\n",
            "[03/10 04:45:15 d2.utils.events]:  eta: 0:01:24  iter: 79  total_loss: 2.023  loss_cls: 0.5627  loss_box_reg: 0.7139  loss_mask: 0.4593  loss_rpn_cls: 0.08662  loss_rpn_loc: 0.1899    time: 0.2019  last_time: 0.2014  data_time: 0.0026  last_data_time: 0.0028   lr: 6.3537e-05  max_mem: 5817M\n",
            "[03/10 04:45:19 d2.utils.events]:  eta: 0:01:23  iter: 99  total_loss: 1.855  loss_cls: 0.4923  loss_box_reg: 0.6638  loss_mask: 0.3676  loss_rpn_cls: 0.1108  loss_rpn_loc: 0.2108    time: 0.2060  last_time: 0.2433  data_time: 0.0025  last_data_time: 0.0026   lr: 7.9521e-05  max_mem: 5817M\n",
            "[03/10 04:45:24 d2.utils.events]:  eta: 0:01:19  iter: 119  total_loss: 1.776  loss_cls: 0.4645  loss_box_reg: 0.6515  loss_mask: 0.3559  loss_rpn_cls: 0.09375  loss_rpn_loc: 0.1804    time: 0.2065  last_time: 0.2096  data_time: 0.0025  last_data_time: 0.0022   lr: 9.5505e-05  max_mem: 5817M\n",
            "[03/10 04:45:28 d2.utils.events]:  eta: 0:01:13  iter: 139  total_loss: 1.65  loss_cls: 0.3724  loss_box_reg: 0.6667  loss_mask: 0.3282  loss_rpn_cls: 0.07265  loss_rpn_loc: 0.158    time: 0.2060  last_time: 0.1912  data_time: 0.0024  last_data_time: 0.0023   lr: 0.00011149  max_mem: 5817M\n",
            "[03/10 04:45:32 d2.utils.events]:  eta: 0:01:08  iter: 159  total_loss: 1.481  loss_cls: 0.3528  loss_box_reg: 0.6325  loss_mask: 0.3272  loss_rpn_cls: 0.06772  loss_rpn_loc: 0.1737    time: 0.2056  last_time: 0.1899  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00012747  max_mem: 5817M\n",
            "[03/10 04:45:36 d2.utils.events]:  eta: 0:01:04  iter: 179  total_loss: 1.584  loss_cls: 0.343  loss_box_reg: 0.6533  loss_mask: 0.3247  loss_rpn_cls: 0.05235  loss_rpn_loc: 0.1887    time: 0.2055  last_time: 0.1668  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00014346  max_mem: 5817M\n",
            "[03/10 04:45:40 d2.utils.events]:  eta: 0:01:01  iter: 199  total_loss: 1.541  loss_cls: 0.2944  loss_box_reg: 0.6725  loss_mask: 0.3031  loss_rpn_cls: 0.07306  loss_rpn_loc: 0.1932    time: 0.2056  last_time: 0.2051  data_time: 0.0026  last_data_time: 0.0029   lr: 0.00015944  max_mem: 5817M\n",
            "[03/10 04:45:44 d2.utils.events]:  eta: 0:00:57  iter: 219  total_loss: 1.371  loss_cls: 0.2845  loss_box_reg: 0.6209  loss_mask: 0.2584  loss_rpn_cls: 0.06196  loss_rpn_loc: 0.179    time: 0.2058  last_time: 0.2183  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00017542  max_mem: 5817M\n",
            "[03/10 04:45:48 d2.utils.events]:  eta: 0:00:53  iter: 239  total_loss: 1.326  loss_cls: 0.2846  loss_box_reg: 0.5315  loss_mask: 0.2444  loss_rpn_cls: 0.03618  loss_rpn_loc: 0.1454    time: 0.2054  last_time: 0.1903  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00019141  max_mem: 5817M\n",
            "[03/10 04:45:52 d2.utils.events]:  eta: 0:00:49  iter: 259  total_loss: 1.269  loss_cls: 0.2962  loss_box_reg: 0.5656  loss_mask: 0.2327  loss_rpn_cls: 0.04068  loss_rpn_loc: 0.1643    time: 0.2049  last_time: 0.1922  data_time: 0.0025  last_data_time: 0.0023   lr: 0.00020739  max_mem: 5817M\n",
            "[03/10 04:45:56 d2.utils.events]:  eta: 0:00:44  iter: 279  total_loss: 1.274  loss_cls: 0.2286  loss_box_reg: 0.551  loss_mask: 0.2141  loss_rpn_cls: 0.03492  loss_rpn_loc: 0.1881    time: 0.2047  last_time: 0.2420  data_time: 0.0024  last_data_time: 0.0022   lr: 0.00022338  max_mem: 5817M\n",
            "[03/10 04:46:00 d2.utils.events]:  eta: 0:00:40  iter: 299  total_loss: 1.175  loss_cls: 0.2203  loss_box_reg: 0.4718  loss_mask: 0.2271  loss_rpn_cls: 0.03325  loss_rpn_loc: 0.199    time: 0.2044  last_time: 0.2159  data_time: 0.0024  last_data_time: 0.0022   lr: 0.00023936  max_mem: 5817M\n",
            "[03/10 04:46:04 d2.utils.events]:  eta: 0:00:36  iter: 319  total_loss: 1.129  loss_cls: 0.2322  loss_box_reg: 0.4679  loss_mask: 0.2116  loss_rpn_cls: 0.03588  loss_rpn_loc: 0.1511    time: 0.2043  last_time: 0.1956  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00025534  max_mem: 5817M\n",
            "[03/10 04:46:08 d2.utils.events]:  eta: 0:00:32  iter: 339  total_loss: 1.106  loss_cls: 0.2027  loss_box_reg: 0.4704  loss_mask: 0.2  loss_rpn_cls: 0.02474  loss_rpn_loc: 0.1546    time: 0.2039  last_time: 0.1929  data_time: 0.0024  last_data_time: 0.0024   lr: 0.00027133  max_mem: 5817M\n",
            "[03/10 04:46:12 d2.utils.events]:  eta: 0:00:28  iter: 359  total_loss: 1.177  loss_cls: 0.237  loss_box_reg: 0.4835  loss_mask: 0.2224  loss_rpn_cls: 0.0306  loss_rpn_loc: 0.1749    time: 0.2038  last_time: 0.1659  data_time: 0.0024  last_data_time: 0.0024   lr: 0.00028731  max_mem: 5817M\n",
            "[03/10 04:46:16 d2.utils.events]:  eta: 0:00:24  iter: 379  total_loss: 0.9064  loss_cls: 0.1713  loss_box_reg: 0.3725  loss_mask: 0.1867  loss_rpn_cls: 0.01935  loss_rpn_loc: 0.167    time: 0.2039  last_time: 0.2316  data_time: 0.0025  last_data_time: 0.0026   lr: 0.0003033  max_mem: 5817M\n",
            "[03/10 04:46:21 d2.utils.events]:  eta: 0:00:20  iter: 399  total_loss: 1.059  loss_cls: 0.2134  loss_box_reg: 0.4068  loss_mask: 0.2063  loss_rpn_cls: 0.0353  loss_rpn_loc: 0.2012    time: 0.2042  last_time: 0.1667  data_time: 0.0025  last_data_time: 0.0026   lr: 0.00031928  max_mem: 5817M\n",
            "[03/10 04:46:25 d2.utils.events]:  eta: 0:00:16  iter: 419  total_loss: 0.9935  loss_cls: 0.1966  loss_box_reg: 0.3996  loss_mask: 0.1864  loss_rpn_cls: 0.03794  loss_rpn_loc: 0.19    time: 0.2042  last_time: 0.1811  data_time: 0.0023  last_data_time: 0.0023   lr: 0.00033526  max_mem: 5817M\n",
            "[03/10 04:46:29 d2.utils.events]:  eta: 0:00:12  iter: 439  total_loss: 0.9875  loss_cls: 0.2267  loss_box_reg: 0.4052  loss_mask: 0.2014  loss_rpn_cls: 0.02184  loss_rpn_loc: 0.1622    time: 0.2047  last_time: 0.2165  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00035125  max_mem: 5817M\n",
            "[03/10 04:46:33 d2.utils.events]:  eta: 0:00:08  iter: 459  total_loss: 0.9873  loss_cls: 0.1795  loss_box_reg: 0.3865  loss_mask: 0.1791  loss_rpn_cls: 0.03477  loss_rpn_loc: 0.1598    time: 0.2045  last_time: 0.1669  data_time: 0.0025  last_data_time: 0.0030   lr: 0.00036723  max_mem: 5817M\n",
            "[03/10 04:46:37 d2.utils.events]:  eta: 0:00:04  iter: 479  total_loss: 0.8397  loss_cls: 0.1841  loss_box_reg: 0.3341  loss_mask: 0.1761  loss_rpn_cls: 0.02427  loss_rpn_loc: 0.1409    time: 0.2042  last_time: 0.1731  data_time: 0.0027  last_data_time: 0.0027   lr: 0.00038322  max_mem: 5817M\n",
            "[03/10 04:46:42 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.9733  loss_cls: 0.1905  loss_box_reg: 0.3973  loss_mask: 0.189  loss_rpn_cls: 0.03693  loss_rpn_loc: 0.1823    time: 0.2044  last_time: 0.2551  data_time: 0.0025  last_data_time: 0.0028   lr: 0.0003992  max_mem: 5817M\n",
            "[03/10 04:46:43 d2.engine.hooks]: Overall training speed: 498 iterations in 0:01:41 (0.2044 s / it)\n",
            "[03/10 04:46:43 d2.engine.hooks]: Total training time: 0:01:43 (0:00:01 on hooks)\n",
            "WARNING [03/10 04:46:43 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:46:43 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold3.json\n",
            "[03/10 04:46:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:46:43 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:46:43 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:46:43 d2.data.common]: Serialized dataset takes 0.11 MiB\n",
            "WARNING [03/10 04:46:43 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "WARNING [03/10 04:46:43 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "WARNING [03/10 04:46:43 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:46:43 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold3.json\n",
            "[03/10 04:46:43 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:46:43 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:46:43 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:46:43 d2.data.common]: Serialized dataset takes 0.11 MiB\n",
            "[03/10 04:46:43 d2.evaluation.evaluator]: Start inference on 20 batches\n",
            "[03/10 04:46:51 d2.evaluation.evaluator]: Inference done 11/20. Dataloading: 0.0013 s/iter. Inference: 0.1964 s/iter. Eval: 0.7420 s/iter. Total: 0.9397 s/iter. ETA=0:00:08\n",
            "[03/10 04:46:56 d2.evaluation.evaluator]: Inference done 19/20. Dataloading: 0.0014 s/iter. Inference: 0.1785 s/iter. Eval: 0.6093 s/iter. Total: 0.7895 s/iter. ETA=0:00:00\n",
            "[03/10 04:46:57 d2.evaluation.evaluator]: Total inference time: 0:00:11.841665 (0.789444 s / iter per device, on 1 devices)\n",
            "[03/10 04:46:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.178106 s / iter per device, on 1 devices)\n",
            "[03/10 04:46:57 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[03/10 04:46:57 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n",
            "[03/10 04:46:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:46:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[03/10 04:46:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n",
            "[03/10 04:46:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:46:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.688\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.977\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.836\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.644\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.741\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.703\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.737\n",
            "[03/10 04:46:57 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 68.751 | 97.731 | 83.607 |  nan  | 64.387 | 68.301 |\n",
            "[03/10 04:46:57 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:46:57 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 62.720 | info       | 74.782 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:46:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[03/10 04:46:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.\n",
            "[03/10 04:46:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:46:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.686\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.977\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.850\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.652\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.479\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.719\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
            "[03/10 04:46:57 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 68.606 | 97.726 | 85.020 |  nan  | 65.246 | 68.784 |\n",
            "[03/10 04:46:57 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:46:57 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 64.842 | info       | 72.370 |\n",
            "Fold 4: AP=68.75, AP50=97.73, AP75=83.61\n",
            "Fold 5 / 5\n",
            "[03/10 04:46:58 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [03/10 04:46:59 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:46:59 d2.data.datasets.coco]: Loaded 80 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train_fold4.json\n",
            "[03/10 04:46:59 d2.data.build]: Removed 0 images with no usable annotations. 80 images left.\n",
            "[03/10 04:46:59 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[03/10 04:46:59 d2.data.build]: Using training sampler TrainingSampler\n",
            "[03/10 04:46:59 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:46:59 d2.data.common]: Serializing 80 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:46:59 d2.data.common]: Serialized dataset takes 0.40 MiB\n",
            "[03/10 04:46:59 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [03/10 04:46:59 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[03/10 04:46:59 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/10 04:46:59 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[03/10 04:47:03 d2.utils.events]:  eta: 0:01:30  iter: 19  total_loss: 6.46  loss_cls: 1.052  loss_box_reg: 0.5352  loss_mask: 0.6899  loss_rpn_cls: 3.586  loss_rpn_loc: 0.4818    time: 0.1919  last_time: 0.2394  data_time: 0.0178  last_data_time: 0.0023   lr: 1.5585e-05  max_mem: 5817M\n",
            "[03/10 04:47:07 d2.utils.events]:  eta: 0:01:29  iter: 39  total_loss: 2.85  loss_cls: 0.9036  loss_box_reg: 0.7524  loss_mask: 0.6448  loss_rpn_cls: 0.2431  loss_rpn_loc: 0.3156    time: 0.1980  last_time: 0.1722  data_time: 0.0026  last_data_time: 0.0026   lr: 3.1569e-05  max_mem: 5817M\n",
            "[03/10 04:47:11 d2.utils.events]:  eta: 0:01:26  iter: 59  total_loss: 2.289  loss_cls: 0.7138  loss_box_reg: 0.6204  loss_mask: 0.5659  loss_rpn_cls: 0.1166  loss_rpn_loc: 0.2409    time: 0.1988  last_time: 0.2185  data_time: 0.0025  last_data_time: 0.0023   lr: 4.7553e-05  max_mem: 5817M\n",
            "[03/10 04:47:15 d2.utils.events]:  eta: 0:01:21  iter: 79  total_loss: 2.1  loss_cls: 0.5985  loss_box_reg: 0.6504  loss_mask: 0.4825  loss_rpn_cls: 0.09082  loss_rpn_loc: 0.18    time: 0.1971  last_time: 0.2005  data_time: 0.0026  last_data_time: 0.0024   lr: 6.3537e-05  max_mem: 5817M\n",
            "[03/10 04:47:19 d2.utils.events]:  eta: 0:01:17  iter: 99  total_loss: 1.92  loss_cls: 0.5062  loss_box_reg: 0.6812  loss_mask: 0.3979  loss_rpn_cls: 0.07926  loss_rpn_loc: 0.195    time: 0.1971  last_time: 0.2270  data_time: 0.0026  last_data_time: 0.0024   lr: 7.9521e-05  max_mem: 5817M\n",
            "[03/10 04:47:23 d2.utils.events]:  eta: 0:01:14  iter: 119  total_loss: 1.826  loss_cls: 0.471  loss_box_reg: 0.6775  loss_mask: 0.3732  loss_rpn_cls: 0.06282  loss_rpn_loc: 0.1787    time: 0.1991  last_time: 0.1718  data_time: 0.0025  last_data_time: 0.0027   lr: 9.5505e-05  max_mem: 5817M\n",
            "[03/10 04:47:27 d2.utils.events]:  eta: 0:01:10  iter: 139  total_loss: 1.654  loss_cls: 0.3769  loss_box_reg: 0.6487  loss_mask: 0.3322  loss_rpn_cls: 0.06905  loss_rpn_loc: 0.1939    time: 0.1999  last_time: 0.1933  data_time: 0.0024  last_data_time: 0.0025   lr: 0.00011149  max_mem: 5817M\n",
            "[03/10 04:47:31 d2.utils.events]:  eta: 0:01:06  iter: 159  total_loss: 1.639  loss_cls: 0.3734  loss_box_reg: 0.6479  loss_mask: 0.3087  loss_rpn_cls: 0.07932  loss_rpn_loc: 0.2224    time: 0.2007  last_time: 0.2189  data_time: 0.0027  last_data_time: 0.0027   lr: 0.00012747  max_mem: 5817M\n",
            "[03/10 04:47:36 d2.utils.events]:  eta: 0:01:03  iter: 179  total_loss: 1.535  loss_cls: 0.3183  loss_box_reg: 0.6606  loss_mask: 0.3135  loss_rpn_cls: 0.05109  loss_rpn_loc: 0.1603    time: 0.2012  last_time: 0.2640  data_time: 0.0026  last_data_time: 0.0028   lr: 0.00014346  max_mem: 5817M\n",
            "[03/10 04:47:39 d2.utils.events]:  eta: 0:00:58  iter: 199  total_loss: 1.499  loss_cls: 0.3115  loss_box_reg: 0.6378  loss_mask: 0.2769  loss_rpn_cls: 0.0397  loss_rpn_loc: 0.1879    time: 0.2006  last_time: 0.1882  data_time: 0.0026  last_data_time: 0.0022   lr: 0.00015944  max_mem: 5817M\n",
            "[03/10 04:47:44 d2.utils.events]:  eta: 0:00:55  iter: 219  total_loss: 1.458  loss_cls: 0.3065  loss_box_reg: 0.595  loss_mask: 0.2836  loss_rpn_cls: 0.05427  loss_rpn_loc: 0.2199    time: 0.2011  last_time: 0.2298  data_time: 0.0028  last_data_time: 0.0027   lr: 0.00017542  max_mem: 5817M\n",
            "[03/10 04:47:48 d2.utils.events]:  eta: 0:00:51  iter: 239  total_loss: 1.309  loss_cls: 0.2649  loss_box_reg: 0.5568  loss_mask: 0.2594  loss_rpn_cls: 0.04364  loss_rpn_loc: 0.1808    time: 0.2012  last_time: 0.2175  data_time: 0.0026  last_data_time: 0.0023   lr: 0.00019141  max_mem: 5817M\n",
            "[03/10 04:47:52 d2.utils.events]:  eta: 0:00:47  iter: 259  total_loss: 1.338  loss_cls: 0.2704  loss_box_reg: 0.5221  loss_mask: 0.2427  loss_rpn_cls: 0.03214  loss_rpn_loc: 0.1768    time: 0.2011  last_time: 0.1778  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00020739  max_mem: 5817M\n",
            "[03/10 04:47:56 d2.utils.events]:  eta: 0:00:43  iter: 279  total_loss: 1.351  loss_cls: 0.2729  loss_box_reg: 0.5213  loss_mask: 0.2367  loss_rpn_cls: 0.04367  loss_rpn_loc: 0.2185    time: 0.2010  last_time: 0.2168  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00022338  max_mem: 5817M\n",
            "[03/10 04:48:00 d2.utils.events]:  eta: 0:00:39  iter: 299  total_loss: 1.238  loss_cls: 0.2501  loss_box_reg: 0.5045  loss_mask: 0.2301  loss_rpn_cls: 0.02812  loss_rpn_loc: 0.1869    time: 0.2011  last_time: 0.2161  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00023936  max_mem: 5817M\n",
            "[03/10 04:48:03 d2.utils.events]:  eta: 0:00:35  iter: 319  total_loss: 1.06  loss_cls: 0.2324  loss_box_reg: 0.4689  loss_mask: 0.1891  loss_rpn_cls: 0.03064  loss_rpn_loc: 0.1528    time: 0.2004  last_time: 0.1768  data_time: 0.0026  last_data_time: 0.0027   lr: 0.00025534  max_mem: 5817M\n",
            "[03/10 04:48:07 d2.utils.events]:  eta: 0:00:31  iter: 339  total_loss: 1.113  loss_cls: 0.2227  loss_box_reg: 0.3972  loss_mask: 0.1815  loss_rpn_cls: 0.02758  loss_rpn_loc: 0.1761    time: 0.2003  last_time: 0.2094  data_time: 0.0027  last_data_time: 0.0025   lr: 0.00027133  max_mem: 5817M\n",
            "[03/10 04:48:12 d2.utils.events]:  eta: 0:00:27  iter: 359  total_loss: 1.126  loss_cls: 0.2436  loss_box_reg: 0.4563  loss_mask: 0.211  loss_rpn_cls: 0.01758  loss_rpn_loc: 0.1716    time: 0.2003  last_time: 0.1875  data_time: 0.0026  last_data_time: 0.0030   lr: 0.00028731  max_mem: 5817M\n",
            "[03/10 04:48:15 d2.utils.events]:  eta: 0:00:23  iter: 379  total_loss: 1.041  loss_cls: 0.1896  loss_box_reg: 0.4281  loss_mask: 0.1986  loss_rpn_cls: 0.02123  loss_rpn_loc: 0.1465    time: 0.2002  last_time: 0.1897  data_time: 0.0025  last_data_time: 0.0027   lr: 0.0003033  max_mem: 5817M\n",
            "[03/10 04:48:20 d2.utils.events]:  eta: 0:00:19  iter: 399  total_loss: 0.9859  loss_cls: 0.1719  loss_box_reg: 0.4161  loss_mask: 0.2034  loss_rpn_cls: 0.03932  loss_rpn_loc: 0.1812    time: 0.2005  last_time: 0.1646  data_time: 0.0025  last_data_time: 0.0028   lr: 0.00031928  max_mem: 5817M\n",
            "[03/10 04:48:23 d2.utils.events]:  eta: 0:00:15  iter: 419  total_loss: 1.012  loss_cls: 0.1724  loss_box_reg: 0.4228  loss_mask: 0.2037  loss_rpn_cls: 0.02959  loss_rpn_loc: 0.1804    time: 0.2001  last_time: 0.1922  data_time: 0.0025  last_data_time: 0.0029   lr: 0.00033526  max_mem: 5817M\n",
            "[03/10 04:48:27 d2.utils.events]:  eta: 0:00:11  iter: 439  total_loss: 0.998  loss_cls: 0.2028  loss_box_reg: 0.3862  loss_mask: 0.1892  loss_rpn_cls: 0.03897  loss_rpn_loc: 0.1883    time: 0.1997  last_time: 0.2301  data_time: 0.0027  last_data_time: 0.0030   lr: 0.00035125  max_mem: 5817M\n",
            "[03/10 04:48:31 d2.utils.events]:  eta: 0:00:07  iter: 459  total_loss: 0.9894  loss_cls: 0.1824  loss_box_reg: 0.3972  loss_mask: 0.1795  loss_rpn_cls: 0.01748  loss_rpn_loc: 0.1729    time: 0.1999  last_time: 0.2385  data_time: 0.0025  last_data_time: 0.0022   lr: 0.00036723  max_mem: 5817M\n",
            "[03/10 04:48:35 d2.utils.events]:  eta: 0:00:03  iter: 479  total_loss: 0.9162  loss_cls: 0.1993  loss_box_reg: 0.3497  loss_mask: 0.1816  loss_rpn_cls: 0.0337  loss_rpn_loc: 0.1735    time: 0.2000  last_time: 0.2201  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00038322  max_mem: 5817M\n",
            "[03/10 04:48:40 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.876  loss_cls: 0.178  loss_box_reg: 0.3406  loss_mask: 0.1916  loss_rpn_cls: 0.0137  loss_rpn_loc: 0.135    time: 0.1998  last_time: 0.1823  data_time: 0.0027  last_data_time: 0.0027   lr: 0.0003992  max_mem: 5817M\n",
            "[03/10 04:48:41 d2.engine.hooks]: Overall training speed: 498 iterations in 0:01:39 (0.1998 s / it)\n",
            "[03/10 04:48:41 d2.engine.hooks]: Total training time: 0:01:41 (0:00:01 on hooks)\n",
            "WARNING [03/10 04:48:41 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:48:41 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold4.json\n",
            "[03/10 04:48:41 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:48:41 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:48:41 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:48:41 d2.data.common]: Serialized dataset takes 0.12 MiB\n",
            "WARNING [03/10 04:48:41 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "WARNING [03/10 04:48:41 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "WARNING [03/10 04:48:41 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:48:41 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold4.json\n",
            "[03/10 04:48:41 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:48:41 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:48:41 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:48:41 d2.data.common]: Serialized dataset takes 0.12 MiB\n",
            "[03/10 04:48:41 d2.evaluation.evaluator]: Start inference on 20 batches\n",
            "[03/10 04:48:49 d2.evaluation.evaluator]: Inference done 11/20. Dataloading: 0.0013 s/iter. Inference: 0.1691 s/iter. Eval: 0.4840 s/iter. Total: 0.6543 s/iter. ETA=0:00:05\n",
            "[03/10 04:48:55 d2.evaluation.evaluator]: Inference done 17/20. Dataloading: 0.0015 s/iter. Inference: 0.1822 s/iter. Eval: 0.6038 s/iter. Total: 0.7877 s/iter. ETA=0:00:02\n",
            "[03/10 04:48:58 d2.evaluation.evaluator]: Total inference time: 0:00:12.344007 (0.822934 s / iter per device, on 1 devices)\n",
            "[03/10 04:48:58 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.185344 s / iter per device, on 1 devices)\n",
            "[03/10 04:48:58 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[03/10 04:48:58 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n",
            "[03/10 04:48:58 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:48:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[03/10 04:48:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.\n",
            "[03/10 04:48:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:48:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.705\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.980\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.873\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.682\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.754\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.745\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
            "[03/10 04:48:58 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 70.465 | 97.980 | 87.318 |  nan  | 68.168 | 69.627 |\n",
            "[03/10 04:48:58 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:48:58 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 67.058 | info       | 73.873 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:48:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[03/10 04:48:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.\n",
            "[03/10 04:48:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:48:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.717\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.980\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.868\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.693\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.707\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.168\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.477\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.766\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.766\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748\n",
            "[03/10 04:48:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 71.665 | 97.989 | 86.786 |  nan  | 69.299 | 70.714 |\n",
            "[03/10 04:48:58 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:48:58 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 67.752 | info       | 75.578 |\n",
            "Fold 5: AP=70.47, AP50=97.98, AP75=87.32\n",
            "\n",
            "Final Cross-validation Results:\n",
            "Mean AP: 63.93\n",
            "Mean AP50: 93.96\n",
            "Mean AP75: 77.48\n"
          ]
        }
      ],
      "source": [
        "# path\n",
        "path = \"/content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train\"\n",
        "path_coco = \"/content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/Organization_annotation.json\"\n",
        "\n",
        "# load data\n",
        "with open(path_coco) as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "annotations = coco_data[\"annotations\"]\n",
        "images = coco_data[\"images\"]\n",
        "\n",
        "# setting for K-fold cross validation\n",
        "K = 5  # num of fold\n",
        "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
        "\n",
        "# Cross validation\n",
        "ap_scores = []\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(images)):\n",
        "    print(f\"Fold {fold + 1} / {K}\")\n",
        "\n",
        "    # split data (train and validation)\n",
        "    train_images = [images[i] for i in train_idx]\n",
        "    val_images = [images[i] for i in val_idx]\n",
        "\n",
        "    train_ids = {img[\"id\"] for img in train_images}\n",
        "    train_annotations = [ann for ann in annotations if ann[\"image_id\"] in train_ids]\n",
        "\n",
        "    val_ids = {img[\"id\"] for img in val_images}\n",
        "    val_annotations = [ann for ann in annotations if ann[\"image_id\"] in val_ids]\n",
        "\n",
        "    train_coco = {\"images\": train_images, \"annotations\": train_annotations, \"categories\": coco_data[\"categories\"]}\n",
        "    val_coco = {\"images\": val_images, \"annotations\": val_annotations, \"categories\": coco_data[\"categories\"]}\n",
        "\n",
        "    # annotation paths\n",
        "    train_coco_path = f\"/content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train_fold{fold}.json\"\n",
        "    val_coco_path = f\"/content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold{fold}.json\"\n",
        "\n",
        "    with open(train_coco_path, \"w\") as f:\n",
        "        json.dump(train_coco, f)\n",
        "    with open(val_coco_path, \"w\") as f:\n",
        "        json.dump(val_coco, f)\n",
        "\n",
        "    # Detectron2\n",
        "    register_coco_instances(f\"org_train_{fold}\", {}, train_coco_path, path)\n",
        "    register_coco_instances(f\"org_val_{fold}\", {}, val_coco_path, path)\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "    cfg.DATASETS.TRAIN = (f\"org_train_{fold}\",)\n",
        "    cfg.DATASETS.TEST = (f\"org_val_{fold}\",)\n",
        "    cfg.DATALOADER.NUM_WORKERS = 2\n",
        "    cfg.SOLVER.IMS_PER_BATCH = 1\n",
        "    cfg.SOLVER.BASE_LR = 0.0004\n",
        "    cfg.SOLVER.MAX_ITER = 500\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "\n",
        "    # train\n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    trainer = DefaultTrainer(cfg)\n",
        "    trainer.resume_or_load(resume=False)\n",
        "    trainer.train()\n",
        "\n",
        "    # evaluation\n",
        "    evaluator = COCOEvaluator(f\"org_val_{fold}\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
        "    val_loader = build_detection_test_loader(cfg, f\"org_val_{fold}\")\n",
        "    eval_results = inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "\n",
        "    # AP\n",
        "    ap = eval_results[\"bbox\"][\"AP\"]      # IoU 50-95: mAP\n",
        "    ap50 = eval_results[\"bbox\"][\"AP50\"]  # IoU 50: AP\n",
        "    ap75 = eval_results[\"bbox\"][\"AP75\"]  # IoU 75: AP\n",
        "\n",
        "    print(f\"Fold {fold + 1}: AP={ap:.2f}, AP50={ap50:.2f}, AP75={ap75:.2f}\")\n",
        "    ap_scores.append((ap, ap50, ap75))\n",
        "\n",
        "# results\n",
        "mean_ap = np.mean([score[0] for score in ap_scores])\n",
        "mean_ap50 = np.mean([score[1] for score in ap_scores])\n",
        "mean_ap75 = np.mean([score[2] for score in ap_scores])\n",
        "\n",
        "print(f\"\\nFinal Cross-validation Results:\")\n",
        "print(f\"Mean AP: {mean_ap:.2f}\")\n",
        "print(f\"Mean AP50: {mean_ap50:.2f}\")\n",
        "print(f\"Mean AP75: {mean_ap75:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}