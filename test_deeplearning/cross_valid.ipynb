{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkpj2O0gFlB4"
      },
      "source": [
        "### Please run with Google Colab with Good GPU\n",
        "<a href=\"https://colab.research.google.com/github/Ichikawa-Satoshi/SI-Org-chart/blob/main/test_deeplearning/cross_valid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cUWebF5mFlB6",
        "outputId": "6dca4f40-8601-401e-b160-f672b80ff510",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "from sklearn.model_selection import KFold\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detectron2 has not released pre-built binaries for the latest pytorch (https://github.com/facebookresearch/detectron2/issues/4053)\n",
        "# so we install from source instead. This takes a few minutes.\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "BURJc3XNF1KU",
        "outputId": "018aef6d-1d07-475b-b9be-e9e37d21d7f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-k9gvw1x1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-k9gvw1x1\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 9604f5995cc628619f0e4fd913453b4d7d61db3f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.5.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.18.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (8.1.8)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (4.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp311-cp311-linux_x86_64.whl size=6380943 sha256=3fb071ececf5d28c95ceb2791ce785bb920bbf3cfaef6683b440a28985b067b6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4z9qh8ku/wheels/17/d9/40/60db98e485aa9455d653e29d1046601ce96fe23647f60c1c5a\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=0e691f85c6b5129132c94c2433ee95b116801a42ba00a84b4823fede522a0dc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=b3f086e3c40088f0376add8bb19c13b0d3e09664d7ec60e63d63afb1363f38fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-25.1.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.1.1 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aMVlc2rLFlB7"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i1DkNU4_FlB8",
        "outputId": "72952c04-ad40-4444-e423-f17f3b3b8965",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 / 5\n",
            "[03/10 03:54:52 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [03/10 03:54:52 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 03:54:52 d2.data.datasets.coco]: Loaded 80 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train_fold0.json\n",
            "[03/10 03:54:52 d2.data.build]: Removed 0 images with no usable annotations. 80 images left.\n",
            "[03/10 03:54:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[03/10 03:54:52 d2.data.build]: Using training sampler TrainingSampler\n",
            "[03/10 03:54:52 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 03:54:52 d2.data.common]: Serializing 80 elements to byte tensors and concatenating them all ...\n",
            "[03/10 03:54:52 d2.data.common]: Serialized dataset takes 0.42 MiB\n",
            "[03/10 03:54:52 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [03/10 03:54:52 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[03/10 03:54:52 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/10 03:54:52 d2.engine.train_loop]: Starting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/10 03:55:03 d2.utils.events]:  eta: 0:01:49  iter: 19  total_loss: 5.898  loss_cls: 1.096  loss_box_reg: 0.5258  loss_mask: 0.6853  loss_rpn_cls: 3.042  loss_rpn_loc: 0.4501    time: 0.3658  last_time: 0.7255  data_time: 0.1918  last_data_time: 0.4941   lr: 1.5585e-05  max_mem: 1304M\n",
            "[03/10 03:55:12 d2.utils.events]:  eta: 0:01:51  iter: 39  total_loss: 2.741  loss_cls: 0.9235  loss_box_reg: 0.6741  loss_mask: 0.6399  loss_rpn_cls: 0.2083  loss_rpn_loc: 0.2843    time: 0.3398  last_time: 0.3009  data_time: 0.1219  last_data_time: 0.0949   lr: 3.1569e-05  max_mem: 1427M\n",
            "[03/10 03:55:20 d2.utils.events]:  eta: 0:02:19  iter: 59  total_loss: 2.31  loss_cls: 0.703  loss_box_reg: 0.612  loss_mask: 0.5651  loss_rpn_cls: 0.129  loss_rpn_loc: 0.2197    time: 0.3544  last_time: 0.3787  data_time: 0.1785  last_data_time: 0.1656   lr: 4.7553e-05  max_mem: 1458M\n",
            "[03/10 03:55:27 d2.utils.events]:  eta: 0:02:12  iter: 79  total_loss: 2.149  loss_cls: 0.572  loss_box_reg: 0.7768  loss_mask: 0.471  loss_rpn_cls: 0.09996  loss_rpn_loc: 0.2195    time: 0.3594  last_time: 0.5581  data_time: 0.1867  last_data_time: 0.3334   lr: 6.3537e-05  max_mem: 1458M\n",
            "[03/10 03:55:32 d2.utils.events]:  eta: 0:01:36  iter: 99  total_loss: 1.856  loss_cls: 0.486  loss_box_reg: 0.6806  loss_mask: 0.3667  loss_rpn_cls: 0.07971  loss_rpn_loc: 0.188    time: 0.3281  last_time: 0.2100  data_time: 0.0022  last_data_time: 0.0024   lr: 7.9521e-05  max_mem: 1458M\n",
            "[03/10 03:55:36 d2.utils.events]:  eta: 0:01:26  iter: 119  total_loss: 1.788  loss_cls: 0.451  loss_box_reg: 0.6787  loss_mask: 0.3525  loss_rpn_cls: 0.09757  loss_rpn_loc: 0.2135    time: 0.3072  last_time: 0.2224  data_time: 0.0026  last_data_time: 0.0027   lr: 9.5505e-05  max_mem: 1458M\n",
            "[03/10 03:55:40 d2.utils.events]:  eta: 0:01:19  iter: 139  total_loss: 1.64  loss_cls: 0.379  loss_box_reg: 0.6446  loss_mask: 0.2997  loss_rpn_cls: 0.0775  loss_rpn_loc: 0.1772    time: 0.2920  last_time: 0.1834  data_time: 0.0024  last_data_time: 0.0024   lr: 0.00011149  max_mem: 1458M\n",
            "[03/10 03:55:44 d2.utils.events]:  eta: 0:01:14  iter: 159  total_loss: 1.452  loss_cls: 0.3371  loss_box_reg: 0.611  loss_mask: 0.3095  loss_rpn_cls: 0.07431  loss_rpn_loc: 0.1793    time: 0.2806  last_time: 0.2314  data_time: 0.0025  last_data_time: 0.0029   lr: 0.00012747  max_mem: 1458M\n",
            "[03/10 03:55:48 d2.utils.events]:  eta: 0:01:09  iter: 179  total_loss: 1.488  loss_cls: 0.2946  loss_box_reg: 0.6343  loss_mask: 0.2981  loss_rpn_cls: 0.04602  loss_rpn_loc: 0.1744    time: 0.2718  last_time: 0.2143  data_time: 0.0025  last_data_time: 0.0028   lr: 0.00014346  max_mem: 1458M\n",
            "[03/10 03:55:52 d2.utils.events]:  eta: 0:01:04  iter: 199  total_loss: 1.328  loss_cls: 0.2967  loss_box_reg: 0.6061  loss_mask: 0.2716  loss_rpn_cls: 0.04288  loss_rpn_loc: 0.144    time: 0.2641  last_time: 0.1880  data_time: 0.0024  last_data_time: 0.0022   lr: 0.00015944  max_mem: 1458M\n",
            "[03/10 03:55:56 d2.utils.events]:  eta: 0:00:59  iter: 219  total_loss: 1.547  loss_cls: 0.3437  loss_box_reg: 0.5995  loss_mask: 0.2832  loss_rpn_cls: 0.04154  loss_rpn_loc: 0.1871    time: 0.2579  last_time: 0.1777  data_time: 0.0026  last_data_time: 0.0029   lr: 0.00017542  max_mem: 1458M\n",
            "[03/10 03:56:00 d2.utils.events]:  eta: 0:00:54  iter: 239  total_loss: 1.32  loss_cls: 0.3181  loss_box_reg: 0.5434  loss_mask: 0.2574  loss_rpn_cls: 0.05187  loss_rpn_loc: 0.1725    time: 0.2533  last_time: 0.2171  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00019141  max_mem: 1458M\n",
            "[03/10 03:56:04 d2.utils.events]:  eta: 0:00:50  iter: 259  total_loss: 1.211  loss_cls: 0.2512  loss_box_reg: 0.5368  loss_mask: 0.2497  loss_rpn_cls: 0.03979  loss_rpn_loc: 0.1613    time: 0.2496  last_time: 0.1772  data_time: 0.0025  last_data_time: 0.0028   lr: 0.00020739  max_mem: 1458M\n",
            "[03/10 03:56:08 d2.utils.events]:  eta: 0:00:46  iter: 279  total_loss: 1.21  loss_cls: 0.2595  loss_box_reg: 0.5242  loss_mask: 0.2204  loss_rpn_cls: 0.02386  loss_rpn_loc: 0.1844    time: 0.2462  last_time: 0.2566  data_time: 0.0024  last_data_time: 0.0023   lr: 0.00022338  max_mem: 1458M\n",
            "[03/10 03:56:12 d2.utils.events]:  eta: 0:00:42  iter: 299  total_loss: 1.141  loss_cls: 0.2496  loss_box_reg: 0.4729  loss_mask: 0.2035  loss_rpn_cls: 0.03141  loss_rpn_loc: 0.1833    time: 0.2431  last_time: 0.1924  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00023936  max_mem: 1458M\n",
            "[03/10 03:56:16 d2.utils.events]:  eta: 0:00:37  iter: 319  total_loss: 1.115  loss_cls: 0.2002  loss_box_reg: 0.4686  loss_mask: 0.1884  loss_rpn_cls: 0.03671  loss_rpn_loc: 0.1597    time: 0.2406  last_time: 0.2152  data_time: 0.0025  last_data_time: 0.0026   lr: 0.00025534  max_mem: 1458M\n",
            "[03/10 03:56:20 d2.utils.events]:  eta: 0:00:33  iter: 339  total_loss: 0.9791  loss_cls: 0.2005  loss_box_reg: 0.4518  loss_mask: 0.2006  loss_rpn_cls: 0.02267  loss_rpn_loc: 0.1562    time: 0.2389  last_time: 0.2258  data_time: 0.0026  last_data_time: 0.0028   lr: 0.00027133  max_mem: 1458M\n",
            "[03/10 03:56:24 d2.utils.events]:  eta: 0:00:29  iter: 359  total_loss: 1.147  loss_cls: 0.223  loss_box_reg: 0.4515  loss_mask: 0.2111  loss_rpn_cls: 0.02887  loss_rpn_loc: 0.181    time: 0.2370  last_time: 0.2181  data_time: 0.0026  last_data_time: 0.0029   lr: 0.00028731  max_mem: 1458M\n",
            "[03/10 03:56:28 d2.utils.events]:  eta: 0:00:25  iter: 379  total_loss: 1.05  loss_cls: 0.1852  loss_box_reg: 0.3955  loss_mask: 0.1959  loss_rpn_cls: 0.03208  loss_rpn_loc: 0.1663    time: 0.2350  last_time: 0.2395  data_time: 0.0026  last_data_time: 0.0026   lr: 0.0003033  max_mem: 1458M\n",
            "[03/10 03:56:32 d2.utils.events]:  eta: 0:00:21  iter: 399  total_loss: 1.029  loss_cls: 0.1945  loss_box_reg: 0.4281  loss_mask: 0.1822  loss_rpn_cls: 0.03289  loss_rpn_loc: 0.1712    time: 0.2333  last_time: 0.2063  data_time: 0.0026  last_data_time: 0.0024   lr: 0.00031928  max_mem: 1458M\n",
            "[03/10 03:56:37 d2.utils.events]:  eta: 0:00:16  iter: 419  total_loss: 0.9609  loss_cls: 0.1891  loss_box_reg: 0.3741  loss_mask: 0.1924  loss_rpn_cls: 0.0216  loss_rpn_loc: 0.1545    time: 0.2319  last_time: 0.2146  data_time: 0.0026  last_data_time: 0.0023   lr: 0.00033526  max_mem: 1458M\n",
            "[03/10 03:56:41 d2.utils.events]:  eta: 0:00:12  iter: 439  total_loss: 0.941  loss_cls: 0.1552  loss_box_reg: 0.3787  loss_mask: 0.1744  loss_rpn_cls: 0.02049  loss_rpn_loc: 0.1617    time: 0.2307  last_time: 0.1954  data_time: 0.0026  last_data_time: 0.0028   lr: 0.00035125  max_mem: 1458M\n",
            "[03/10 03:56:45 d2.utils.events]:  eta: 0:00:08  iter: 459  total_loss: 1.014  loss_cls: 0.2118  loss_box_reg: 0.4324  loss_mask: 0.1825  loss_rpn_cls: 0.02139  loss_rpn_loc: 0.1766    time: 0.2294  last_time: 0.1949  data_time: 0.0026  last_data_time: 0.0024   lr: 0.00036723  max_mem: 1462M\n",
            "[03/10 03:56:49 d2.utils.events]:  eta: 0:00:04  iter: 479  total_loss: 0.9159  loss_cls: 0.1675  loss_box_reg: 0.3858  loss_mask: 0.1784  loss_rpn_cls: 0.03603  loss_rpn_loc: 0.1469    time: 0.2282  last_time: 0.2390  data_time: 0.0025  last_data_time: 0.0030   lr: 0.00038322  max_mem: 1527M\n",
            "[03/10 03:56:53 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.9148  loss_cls: 0.1704  loss_box_reg: 0.3791  loss_mask: 0.188  loss_rpn_cls: 0.01993  loss_rpn_loc: 0.1604    time: 0.2269  last_time: 0.1835  data_time: 0.0028  last_data_time: 0.0028   lr: 0.0003992  max_mem: 1527M\n",
            "[03/10 03:56:53 d2.engine.hooks]: Overall training speed: 498 iterations in 0:01:52 (0.2269 s / it)\n",
            "[03/10 03:56:53 d2.engine.hooks]: Total training time: 0:01:57 (0:00:04 on hooks)\n",
            "WARNING [03/10 03:56:53 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 03:56:53 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold0.json\n",
            "[03/10 03:56:53 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|\n",
            "| department | 741          |    info    | 35           |\n",
            "|            |              |            |              |\n",
            "|   total    | 776          |            |              |\n",
            "[03/10 03:56:53 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 03:56:53 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 03:56:53 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 03:56:53 d2.data.common]: Serialized dataset takes 0.10 MiB\n",
            "WARNING [03/10 03:56:53 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "WARNING [03/10 03:56:53 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "WARNING [03/10 03:56:53 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 03:56:53 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold0.json\n",
            "[03/10 03:56:53 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 03:56:53 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 03:56:53 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 03:56:53 d2.data.common]: Serialized dataset takes 0.10 MiB\n",
            "[03/10 03:56:53 d2.evaluation.evaluator]: Start inference on 20 batches\n",
            "[03/10 03:57:00 d2.evaluation.evaluator]: Inference done 11/20. Dataloading: 0.0013 s/iter. Inference: 0.1317 s/iter. Eval: 0.2923 s/iter. Total: 0.4254 s/iter. ETA=0:00:03\n",
            "[03/10 03:57:06 d2.evaluation.evaluator]: Inference done 18/20. Dataloading: 0.0014 s/iter. Inference: 0.1594 s/iter. Eval: 0.4843 s/iter. Total: 0.6454 s/iter. ETA=0:00:01\n",
            "[03/10 03:57:08 d2.evaluation.evaluator]: Total inference time: 0:00:10.362705 (0.690847 s / iter per device, on 1 devices)\n",
            "[03/10 03:57:08 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.164589 s / iter per device, on 1 devices)\n",
            "[03/10 03:57:08 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[03/10 03:57:08 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n",
            "[03/10 03:57:08 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 03:57:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[03/10 03:57:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n",
            "[03/10 03:57:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 03:57:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.928\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.745\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.516\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.440\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.608\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679\n",
            "[03/10 03:57:08 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 61.338 | 92.838 | 74.452 |  nan  | 51.629 | 64.629 |\n",
            "[03/10 03:57:08 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 03:57:08 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 53.466 | info       | 69.210 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 03:57:08 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[03/10 03:57:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.\n",
            "[03/10 03:57:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 03:57:08 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.619\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.928\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.747\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.514\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.651\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.441\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678\n",
            "[03/10 03:57:08 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 61.927 | 92.798 | 74.690 |  nan  | 51.360 | 65.145 |\n",
            "[03/10 03:57:08 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 03:57:08 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 53.026 | info       | 70.827 |\n",
            "Fold 1: AP=61.34, AP50=92.84, AP75=74.45\n",
            "Fold 2 / 5\n",
            "[03/10 03:57:09 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [03/10 03:57:09 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 03:57:09 d2.data.datasets.coco]: Loaded 80 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train_fold1.json\n",
            "[03/10 03:57:09 d2.data.build]: Removed 0 images with no usable annotations. 80 images left.\n",
            "[03/10 03:57:09 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|\n",
            "| department | 2975         |    info    | 149          |\n",
            "|            |              |            |              |\n",
            "|   total    | 3124         |            |              |\n",
            "[03/10 03:57:09 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[03/10 03:57:09 d2.data.build]: Using training sampler TrainingSampler\n",
            "[03/10 03:57:09 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 03:57:09 d2.data.common]: Serializing 80 elements to byte tensors and concatenating them all ...\n",
            "[03/10 03:57:09 d2.data.common]: Serialized dataset takes 0.40 MiB\n",
            "[03/10 03:57:09 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [03/10 03:57:09 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[03/10 03:57:09 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/10 03:57:09 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[03/10 03:57:14 d2.utils.events]:  eta: 0:01:29  iter: 19  total_loss: 6.058  loss_cls: 1.028  loss_box_reg: 0.6013  loss_mask: 0.685  loss_rpn_cls: 3.519  loss_rpn_loc: 0.4249    time: 0.1907  last_time: 0.2197  data_time: 0.0188  last_data_time: 0.0023   lr: 1.5585e-05  max_mem: 4314M\n",
            "[03/10 03:57:18 d2.utils.events]:  eta: 0:01:27  iter: 39  total_loss: 2.856  loss_cls: 0.8958  loss_box_reg: 0.6752  loss_mask: 0.636  loss_rpn_cls: 0.2428  loss_rpn_loc: 0.3226    time: 0.1988  last_time: 0.2204  data_time: 0.0025  last_data_time: 0.0023   lr: 3.1569e-05  max_mem: 4314M\n",
            "[03/10 03:57:22 d2.utils.events]:  eta: 0:01:25  iter: 59  total_loss: 2.267  loss_cls: 0.6907  loss_box_reg: 0.675  loss_mask: 0.5587  loss_rpn_cls: 0.08727  loss_rpn_loc: 0.2409    time: 0.2003  last_time: 0.1981  data_time: 0.0025  last_data_time: 0.0024   lr: 4.7553e-05  max_mem: 4314M\n",
            "[03/10 03:57:26 d2.utils.events]:  eta: 0:01:22  iter: 79  total_loss: 2.078  loss_cls: 0.57  loss_box_reg: 0.7095  loss_mask: 0.4792  loss_rpn_cls: 0.08208  loss_rpn_loc: 0.1966    time: 0.2004  last_time: 0.2169  data_time: 0.0024  last_data_time: 0.0027   lr: 6.3537e-05  max_mem: 4314M\n",
            "[03/10 03:57:30 d2.utils.events]:  eta: 0:01:19  iter: 99  total_loss: 1.888  loss_cls: 0.475  loss_box_reg: 0.636  loss_mask: 0.3746  loss_rpn_cls: 0.09421  loss_rpn_loc: 0.2068    time: 0.2021  last_time: 0.2393  data_time: 0.0025  last_data_time: 0.0028   lr: 7.9521e-05  max_mem: 4314M\n",
            "[03/10 03:57:34 d2.utils.events]:  eta: 0:01:15  iter: 119  total_loss: 1.685  loss_cls: 0.4199  loss_box_reg: 0.593  loss_mask: 0.3363  loss_rpn_cls: 0.0805  loss_rpn_loc: 0.1784    time: 0.2021  last_time: 0.1985  data_time: 0.0027  last_data_time: 0.0030   lr: 9.5505e-05  max_mem: 4314M\n",
            "[03/10 03:57:38 d2.utils.events]:  eta: 0:01:11  iter: 139  total_loss: 1.652  loss_cls: 0.3447  loss_box_reg: 0.697  loss_mask: 0.3352  loss_rpn_cls: 0.06969  loss_rpn_loc: 0.1807    time: 0.2012  last_time: 0.1770  data_time: 0.0026  last_data_time: 0.0025   lr: 0.00011149  max_mem: 4314M\n",
            "[03/10 03:57:42 d2.utils.events]:  eta: 0:01:07  iter: 159  total_loss: 1.399  loss_cls: 0.3167  loss_box_reg: 0.5886  loss_mask: 0.3124  loss_rpn_cls: 0.03813  loss_rpn_loc: 0.1506    time: 0.2010  last_time: 0.2330  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00012747  max_mem: 4314M\n",
            "[03/10 03:57:46 d2.utils.events]:  eta: 0:01:03  iter: 179  total_loss: 1.654  loss_cls: 0.3454  loss_box_reg: 0.6698  loss_mask: 0.3012  loss_rpn_cls: 0.05407  loss_rpn_loc: 0.1839    time: 0.2006  last_time: 0.1835  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00014346  max_mem: 4314M\n",
            "[03/10 03:57:50 d2.utils.events]:  eta: 0:00:59  iter: 199  total_loss: 1.458  loss_cls: 0.2936  loss_box_reg: 0.6187  loss_mask: 0.2878  loss_rpn_cls: 0.05087  loss_rpn_loc: 0.1735    time: 0.2008  last_time: 0.1662  data_time: 0.0024  last_data_time: 0.0023   lr: 0.00015944  max_mem: 4314M\n",
            "[03/10 03:57:54 d2.utils.events]:  eta: 0:00:55  iter: 219  total_loss: 1.3  loss_cls: 0.2535  loss_box_reg: 0.564  loss_mask: 0.2404  loss_rpn_cls: 0.03712  loss_rpn_loc: 0.1505    time: 0.2017  last_time: 0.1664  data_time: 0.0023  last_data_time: 0.0024   lr: 0.00017542  max_mem: 4314M\n",
            "[03/10 03:57:58 d2.utils.events]:  eta: 0:00:51  iter: 239  total_loss: 1.21  loss_cls: 0.258  loss_box_reg: 0.5277  loss_mask: 0.2523  loss_rpn_cls: 0.04068  loss_rpn_loc: 0.1582    time: 0.2018  last_time: 0.1979  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00019141  max_mem: 4314M\n",
            "[03/10 03:58:02 d2.utils.events]:  eta: 0:00:47  iter: 259  total_loss: 1.238  loss_cls: 0.2692  loss_box_reg: 0.5144  loss_mask: 0.2355  loss_rpn_cls: 0.05559  loss_rpn_loc: 0.1683    time: 0.2014  last_time: 0.1758  data_time: 0.0024  last_data_time: 0.0023   lr: 0.00020739  max_mem: 4314M\n",
            "[03/10 03:58:06 d2.utils.events]:  eta: 0:00:43  iter: 279  total_loss: 1.121  loss_cls: 0.259  loss_box_reg: 0.4863  loss_mask: 0.204  loss_rpn_cls: 0.03167  loss_rpn_loc: 0.1645    time: 0.2007  last_time: 0.1731  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00022338  max_mem: 4314M\n",
            "[03/10 03:58:10 d2.utils.events]:  eta: 0:00:39  iter: 299  total_loss: 1.125  loss_cls: 0.2306  loss_box_reg: 0.4884  loss_mask: 0.2167  loss_rpn_cls: 0.03  loss_rpn_loc: 0.2042    time: 0.2010  last_time: 0.1883  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00023936  max_mem: 4314M\n",
            "[03/10 03:58:14 d2.utils.events]:  eta: 0:00:35  iter: 319  total_loss: 1.008  loss_cls: 0.1977  loss_box_reg: 0.4291  loss_mask: 0.1942  loss_rpn_cls: 0.03592  loss_rpn_loc: 0.1493    time: 0.2011  last_time: 0.2312  data_time: 0.0025  last_data_time: 0.0026   lr: 0.00025534  max_mem: 4314M\n",
            "[03/10 03:58:18 d2.utils.events]:  eta: 0:00:31  iter: 339  total_loss: 1.022  loss_cls: 0.2073  loss_box_reg: 0.4351  loss_mask: 0.2039  loss_rpn_cls: 0.02239  loss_rpn_loc: 0.1542    time: 0.2007  last_time: 0.1751  data_time: 0.0024  last_data_time: 0.0026   lr: 0.00027133  max_mem: 4314M\n",
            "[03/10 03:58:22 d2.utils.events]:  eta: 0:00:27  iter: 359  total_loss: 0.9647  loss_cls: 0.2024  loss_box_reg: 0.3732  loss_mask: 0.1821  loss_rpn_cls: 0.02057  loss_rpn_loc: 0.1782    time: 0.2003  last_time: 0.1705  data_time: 0.0026  last_data_time: 0.0029   lr: 0.00028731  max_mem: 4314M\n",
            "[03/10 03:58:26 d2.utils.events]:  eta: 0:00:23  iter: 379  total_loss: 0.9938  loss_cls: 0.2146  loss_box_reg: 0.4291  loss_mask: 0.1904  loss_rpn_cls: 0.02799  loss_rpn_loc: 0.1599    time: 0.2005  last_time: 0.2085  data_time: 0.0025  last_data_time: 0.0022   lr: 0.0003033  max_mem: 4314M\n",
            "[03/10 03:58:30 d2.utils.events]:  eta: 0:00:19  iter: 399  total_loss: 0.9885  loss_cls: 0.2  loss_box_reg: 0.417  loss_mask: 0.1842  loss_rpn_cls: 0.02525  loss_rpn_loc: 0.1521    time: 0.2007  last_time: 0.1650  data_time: 0.0026  last_data_time: 0.0024   lr: 0.00031928  max_mem: 4314M\n",
            "[03/10 03:58:34 d2.utils.events]:  eta: 0:00:15  iter: 419  total_loss: 1.031  loss_cls: 0.2083  loss_box_reg: 0.407  loss_mask: 0.1749  loss_rpn_cls: 0.0338  loss_rpn_loc: 0.2041    time: 0.2004  last_time: 0.1846  data_time: 0.0025  last_data_time: 0.0026   lr: 0.00033526  max_mem: 4314M\n",
            "[03/10 03:58:39 d2.utils.events]:  eta: 0:00:11  iter: 439  total_loss: 0.81  loss_cls: 0.1427  loss_box_reg: 0.3352  loss_mask: 0.1692  loss_rpn_cls: 0.01731  loss_rpn_loc: 0.1493    time: 0.2009  last_time: 0.1681  data_time: 0.0026  last_data_time: 0.0024   lr: 0.00035125  max_mem: 4314M\n",
            "[03/10 03:58:43 d2.utils.events]:  eta: 0:00:07  iter: 459  total_loss: 0.9723  loss_cls: 0.1802  loss_box_reg: 0.4228  loss_mask: 0.1674  loss_rpn_cls: 0.01367  loss_rpn_loc: 0.173    time: 0.2008  last_time: 0.2390  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00036723  max_mem: 4314M\n",
            "[03/10 03:58:47 d2.utils.events]:  eta: 0:00:03  iter: 479  total_loss: 0.8184  loss_cls: 0.1352  loss_box_reg: 0.3289  loss_mask: 0.1742  loss_rpn_cls: 0.01592  loss_rpn_loc: 0.1454    time: 0.2008  last_time: 0.2105  data_time: 0.0025  last_data_time: 0.0030   lr: 0.00038322  max_mem: 4314M\n",
            "[03/10 03:58:51 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.8733  loss_cls: 0.1545  loss_box_reg: 0.3735  loss_mask: 0.1716  loss_rpn_cls: 0.01777  loss_rpn_loc: 0.1418    time: 0.2007  last_time: 0.1642  data_time: 0.0024  last_data_time: 0.0026   lr: 0.0003992  max_mem: 4314M\n",
            "[03/10 03:58:52 d2.engine.hooks]: Overall training speed: 498 iterations in 0:01:39 (0.2007 s / it)\n",
            "[03/10 03:58:52 d2.engine.hooks]: Total training time: 0:01:41 (0:00:01 on hooks)\n",
            "WARNING [03/10 03:58:52 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 03:58:52 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold1.json\n",
            "[03/10 03:58:52 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|\n",
            "| department | 871          |    info    | 45           |\n",
            "|            |              |            |              |\n",
            "|   total    | 916          |            |              |\n",
            "[03/10 03:58:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 03:58:52 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 03:58:52 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 03:58:52 d2.data.common]: Serialized dataset takes 0.12 MiB\n",
            "WARNING [03/10 03:58:52 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "WARNING [03/10 03:58:52 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "WARNING [03/10 03:58:52 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 03:58:52 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold1.json\n",
            "[03/10 03:58:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 03:58:52 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 03:58:52 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 03:58:52 d2.data.common]: Serialized dataset takes 0.12 MiB\n",
            "[03/10 03:58:52 d2.evaluation.evaluator]: Start inference on 20 batches\n",
            "[03/10 03:58:59 d2.evaluation.evaluator]: Inference done 11/20. Dataloading: 0.0013 s/iter. Inference: 0.1271 s/iter. Eval: 0.2537 s/iter. Total: 0.3821 s/iter. ETA=0:00:03\n",
            "[03/10 03:59:04 d2.evaluation.evaluator]: Inference done 17/20. Dataloading: 0.0014 s/iter. Inference: 0.1626 s/iter. Eval: 0.4836 s/iter. Total: 0.6477 s/iter. ETA=0:00:01\n",
            "[03/10 03:59:07 d2.evaluation.evaluator]: Total inference time: 0:00:10.638771 (0.709251 s / iter per device, on 1 devices)\n",
            "[03/10 03:59:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.169496 s / iter per device, on 1 devices)\n",
            "[03/10 03:59:07 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[03/10 03:59:07 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n",
            "[03/10 03:59:07 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 03:59:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[03/10 03:59:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.\n",
            "[03/10 03:59:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 03:59:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.916\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.692\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.622\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.684\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.565\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685\n",
            "[03/10 03:59:07 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 61.203 | 91.643 | 69.159 | 3.333 | 45.988 | 62.230 |\n",
            "[03/10 03:59:07 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 46.268 | info       | 76.137 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 03:59:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[03/10 03:59:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.\n",
            "[03/10 03:59:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 03:59:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.603\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.902\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.682\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.141\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.676\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.572\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.671\n",
            "[03/10 03:59:07 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 60.320 | 90.214 | 68.175 | 2.500 | 45.792 | 61.043 |\n",
            "[03/10 03:59:07 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 45.806 | info       | 74.833 |\n",
            "Fold 2: AP=61.20, AP50=91.64, AP75=69.16\n",
            "Fold 3 / 5\n",
            "[03/10 03:59:08 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [03/10 03:59:08 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 03:59:08 d2.data.datasets.coco]: Loaded 80 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train_fold2.json\n",
            "[03/10 03:59:08 d2.data.build]: Removed 0 images with no usable annotations. 80 images left.\n",
            "[03/10 03:59:08 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|\n",
            "| department | 3205         |    info    | 162          |\n",
            "|            |              |            |              |\n",
            "|   total    | 3367         |            |              |\n",
            "[03/10 03:59:08 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[03/10 03:59:08 d2.data.build]: Using training sampler TrainingSampler\n",
            "[03/10 03:59:08 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 03:59:08 d2.data.common]: Serializing 80 elements to byte tensors and concatenating them all ...\n",
            "[03/10 03:59:08 d2.data.common]: Serialized dataset takes 0.44 MiB\n",
            "[03/10 03:59:08 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [03/10 03:59:08 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[03/10 03:59:08 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/10 03:59:09 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[03/10 03:59:13 d2.utils.events]:  eta: 0:01:41  iter: 19  total_loss: 5.787  loss_cls: 1.031  loss_box_reg: 0.5272  loss_mask: 0.6921  loss_rpn_cls: 3.017  loss_rpn_loc: 0.3833    time: 0.2032  last_time: 0.1483  data_time: 0.0184  last_data_time: 0.0024   lr: 1.5585e-05  max_mem: 4314M\n",
            "[03/10 03:59:17 d2.utils.events]:  eta: 0:01:29  iter: 39  total_loss: 2.761  loss_cls: 0.8781  loss_box_reg: 0.6924  loss_mask: 0.6446  loss_rpn_cls: 0.2999  loss_rpn_loc: 0.2575    time: 0.1972  last_time: 0.2081  data_time: 0.0025  last_data_time: 0.0024   lr: 3.1569e-05  max_mem: 4314M\n",
            "[03/10 03:59:21 d2.utils.events]:  eta: 0:01:28  iter: 59  total_loss: 2.194  loss_cls: 0.6994  loss_box_reg: 0.6428  loss_mask: 0.5658  loss_rpn_cls: 0.1191  loss_rpn_loc: 0.215    time: 0.1986  last_time: 0.1766  data_time: 0.0026  last_data_time: 0.0027   lr: 4.7553e-05  max_mem: 4314M\n",
            "[03/10 03:59:25 d2.utils.events]:  eta: 0:01:24  iter: 79  total_loss: 2.12  loss_cls: 0.5688  loss_box_reg: 0.7108  loss_mask: 0.4718  loss_rpn_cls: 0.07616  loss_rpn_loc: 0.2254    time: 0.2004  last_time: 0.2151  data_time: 0.0025  last_data_time: 0.0024   lr: 6.3537e-05  max_mem: 4314M\n",
            "[03/10 03:59:29 d2.utils.events]:  eta: 0:01:21  iter: 99  total_loss: 1.836  loss_cls: 0.4865  loss_box_reg: 0.716  loss_mask: 0.3902  loss_rpn_cls: 0.06715  loss_rpn_loc: 0.1903    time: 0.2022  last_time: 0.1916  data_time: 0.0025  last_data_time: 0.0024   lr: 7.9521e-05  max_mem: 4314M\n",
            "[03/10 03:59:33 d2.utils.events]:  eta: 0:01:17  iter: 119  total_loss: 1.831  loss_cls: 0.4456  loss_box_reg: 0.6297  loss_mask: 0.3383  loss_rpn_cls: 0.1215  loss_rpn_loc: 0.2004    time: 0.2029  last_time: 0.1954  data_time: 0.0026  last_data_time: 0.0026   lr: 9.5505e-05  max_mem: 4314M\n",
            "[03/10 03:59:37 d2.utils.events]:  eta: 0:01:12  iter: 139  total_loss: 1.707  loss_cls: 0.4005  loss_box_reg: 0.651  loss_mask: 0.3295  loss_rpn_cls: 0.05959  loss_rpn_loc: 0.1805    time: 0.2029  last_time: 0.2142  data_time: 0.0025  last_data_time: 0.0023   lr: 0.00011149  max_mem: 4314M\n",
            "[03/10 03:59:42 d2.utils.events]:  eta: 0:01:10  iter: 159  total_loss: 1.491  loss_cls: 0.3442  loss_box_reg: 0.5885  loss_mask: 0.3176  loss_rpn_cls: 0.05108  loss_rpn_loc: 0.1536    time: 0.2043  last_time: 0.2419  data_time: 0.0026  last_data_time: 0.0026   lr: 0.00012747  max_mem: 4314M\n",
            "[03/10 03:59:46 d2.utils.events]:  eta: 0:01:05  iter: 179  total_loss: 1.508  loss_cls: 0.3463  loss_box_reg: 0.6276  loss_mask: 0.2969  loss_rpn_cls: 0.0612  loss_rpn_loc: 0.1523    time: 0.2042  last_time: 0.1996  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00014346  max_mem: 4314M\n",
            "[03/10 03:59:50 d2.utils.events]:  eta: 0:01:01  iter: 199  total_loss: 1.499  loss_cls: 0.3275  loss_box_reg: 0.6024  loss_mask: 0.2907  loss_rpn_cls: 0.04836  loss_rpn_loc: 0.1726    time: 0.2034  last_time: 0.1649  data_time: 0.0024  last_data_time: 0.0026   lr: 0.00015944  max_mem: 4314M\n",
            "[03/10 03:59:54 d2.utils.events]:  eta: 0:00:57  iter: 219  total_loss: 1.385  loss_cls: 0.2839  loss_box_reg: 0.6008  loss_mask: 0.2684  loss_rpn_cls: 0.03846  loss_rpn_loc: 0.1564    time: 0.2039  last_time: 0.1921  data_time: 0.0024  last_data_time: 0.0026   lr: 0.00017542  max_mem: 4314M\n",
            "[03/10 03:59:58 d2.utils.events]:  eta: 0:00:52  iter: 239  total_loss: 1.212  loss_cls: 0.2625  loss_box_reg: 0.5371  loss_mask: 0.244  loss_rpn_cls: 0.03715  loss_rpn_loc: 0.1666    time: 0.2036  last_time: 0.2406  data_time: 0.0026  last_data_time: 0.0023   lr: 0.00019141  max_mem: 4314M\n",
            "[03/10 04:00:02 d2.utils.events]:  eta: 0:00:48  iter: 259  total_loss: 1.288  loss_cls: 0.2522  loss_box_reg: 0.5572  loss_mask: 0.2465  loss_rpn_cls: 0.03289  loss_rpn_loc: 0.1603    time: 0.2034  last_time: 0.1639  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00020739  max_mem: 4314M\n",
            "[03/10 04:00:06 d2.utils.events]:  eta: 0:00:44  iter: 279  total_loss: 1.189  loss_cls: 0.2215  loss_box_reg: 0.5053  loss_mask: 0.2256  loss_rpn_cls: 0.02574  loss_rpn_loc: 0.1609    time: 0.2033  last_time: 0.1767  data_time: 0.0026  last_data_time: 0.0024   lr: 0.00022338  max_mem: 4314M\n",
            "[03/10 04:00:10 d2.utils.events]:  eta: 0:00:40  iter: 299  total_loss: 1.218  loss_cls: 0.2457  loss_box_reg: 0.5208  loss_mask: 0.217  loss_rpn_cls: 0.03089  loss_rpn_loc: 0.1758    time: 0.2030  last_time: 0.1818  data_time: 0.0027  last_data_time: 0.0024   lr: 0.00023936  max_mem: 4314M\n",
            "[03/10 04:00:14 d2.utils.events]:  eta: 0:00:36  iter: 319  total_loss: 1.068  loss_cls: 0.2144  loss_box_reg: 0.4629  loss_mask: 0.1944  loss_rpn_cls: 0.02827  loss_rpn_loc: 0.1447    time: 0.2036  last_time: 0.1834  data_time: 0.0026  last_data_time: 0.0024   lr: 0.00025534  max_mem: 4314M\n",
            "[03/10 04:00:18 d2.utils.events]:  eta: 0:00:32  iter: 339  total_loss: 0.9927  loss_cls: 0.2089  loss_box_reg: 0.4235  loss_mask: 0.1822  loss_rpn_cls: 0.02048  loss_rpn_loc: 0.1805    time: 0.2029  last_time: 0.1856  data_time: 0.0025  last_data_time: 0.0026   lr: 0.00027133  max_mem: 4314M\n",
            "[03/10 04:00:22 d2.utils.events]:  eta: 0:00:28  iter: 359  total_loss: 1.173  loss_cls: 0.243  loss_box_reg: 0.4962  loss_mask: 0.2152  loss_rpn_cls: 0.02122  loss_rpn_loc: 0.1777    time: 0.2024  last_time: 0.1889  data_time: 0.0025  last_data_time: 0.0023   lr: 0.00028731  max_mem: 4314M\n",
            "[03/10 04:00:26 d2.utils.events]:  eta: 0:00:24  iter: 379  total_loss: 1.054  loss_cls: 0.2203  loss_box_reg: 0.4577  loss_mask: 0.2045  loss_rpn_cls: 0.01694  loss_rpn_loc: 0.1541    time: 0.2019  last_time: 0.1523  data_time: 0.0024  last_data_time: 0.0023   lr: 0.0003033  max_mem: 4314M\n",
            "[03/10 04:00:30 d2.utils.events]:  eta: 0:00:20  iter: 399  total_loss: 1.038  loss_cls: 0.1897  loss_box_reg: 0.3811  loss_mask: 0.1928  loss_rpn_cls: 0.01984  loss_rpn_loc: 0.1845    time: 0.2020  last_time: 0.1617  data_time: 0.0025  last_data_time: 0.0023   lr: 0.00031928  max_mem: 4314M\n",
            "[03/10 04:00:34 d2.utils.events]:  eta: 0:00:16  iter: 419  total_loss: 1.039  loss_cls: 0.1912  loss_box_reg: 0.3823  loss_mask: 0.1852  loss_rpn_cls: 0.02358  loss_rpn_loc: 0.1805    time: 0.2019  last_time: 0.1758  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00033526  max_mem: 4314M\n",
            "[03/10 04:00:38 d2.utils.events]:  eta: 0:00:12  iter: 439  total_loss: 0.8692  loss_cls: 0.1714  loss_box_reg: 0.3743  loss_mask: 0.176  loss_rpn_cls: 0.02407  loss_rpn_loc: 0.1542    time: 0.2017  last_time: 0.2260  data_time: 0.0025  last_data_time: 0.0023   lr: 0.00035125  max_mem: 4314M\n",
            "[03/10 04:00:42 d2.utils.events]:  eta: 0:00:08  iter: 459  total_loss: 0.9506  loss_cls: 0.1885  loss_box_reg: 0.3496  loss_mask: 0.1842  loss_rpn_cls: 0.01928  loss_rpn_loc: 0.1796    time: 0.2020  last_time: 0.2212  data_time: 0.0026  last_data_time: 0.0022   lr: 0.00036723  max_mem: 4314M\n",
            "[03/10 04:00:46 d2.utils.events]:  eta: 0:00:04  iter: 479  total_loss: 0.8291  loss_cls: 0.1565  loss_box_reg: 0.3647  loss_mask: 0.1579  loss_rpn_cls: 0.01779  loss_rpn_loc: 0.1765    time: 0.2022  last_time: 0.2410  data_time: 0.0027  last_data_time: 0.0029   lr: 0.00038322  max_mem: 4314M\n",
            "[03/10 04:00:51 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.9309  loss_cls: 0.1477  loss_box_reg: 0.3895  loss_mask: 0.1731  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.1728    time: 0.2024  last_time: 0.2203  data_time: 0.0026  last_data_time: 0.0025   lr: 0.0003992  max_mem: 4314M\n",
            "[03/10 04:00:52 d2.engine.hooks]: Overall training speed: 498 iterations in 0:01:40 (0.2024 s / it)\n",
            "[03/10 04:00:52 d2.engine.hooks]: Total training time: 0:01:42 (0:00:01 on hooks)\n",
            "WARNING [03/10 04:00:52 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:00:52 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold2.json\n",
            "[03/10 04:00:52 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|\n",
            "| department | 641          |    info    | 32           |\n",
            "|            |              |            |              |\n",
            "|   total    | 673          |            |              |\n",
            "[03/10 04:00:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:00:52 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:00:52 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:00:52 d2.data.common]: Serialized dataset takes 0.08 MiB\n",
            "WARNING [03/10 04:00:52 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "WARNING [03/10 04:00:52 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "WARNING [03/10 04:00:52 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:00:52 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold2.json\n",
            "[03/10 04:00:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:00:52 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:00:52 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:00:52 d2.data.common]: Serialized dataset takes 0.08 MiB\n",
            "[03/10 04:00:52 d2.evaluation.evaluator]: Start inference on 20 batches\n",
            "[03/10 04:00:59 d2.evaluation.evaluator]: Inference done 11/20. Dataloading: 0.0014 s/iter. Inference: 0.1380 s/iter. Eval: 0.3049 s/iter. Total: 0.4443 s/iter. ETA=0:00:03\n",
            "[03/10 04:01:04 d2.evaluation.evaluator]: Inference done 19/20. Dataloading: 0.0014 s/iter. Inference: 0.1522 s/iter. Eval: 0.4076 s/iter. Total: 0.5614 s/iter. ETA=0:00:00\n",
            "[03/10 04:01:05 d2.evaluation.evaluator]: Total inference time: 0:00:08.640388 (0.576026 s / iter per device, on 1 devices)\n",
            "[03/10 04:01:05 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.153169 s / iter per device, on 1 devices)\n",
            "[03/10 04:01:05 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[03/10 04:01:05 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n",
            "[03/10 04:01:05 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:01:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[03/10 04:01:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n",
            "[03/10 04:01:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:01:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.580\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.915\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.632\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.553\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654\n",
            "[03/10 04:01:05 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 58.048 | 91.507 | 63.236 |  nan  | 37.203 | 60.790 |\n",
            "[03/10 04:01:05 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:01:05 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 42.152 | info       | 73.944 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:01:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[03/10 04:01:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.\n",
            "[03/10 04:01:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:01:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.591\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.895\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.635\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.154\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.671\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.663\n",
            "[03/10 04:01:05 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 59.086 | 89.515 | 63.474 |  nan  | 36.393 | 61.625 |\n",
            "[03/10 04:01:05 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:01:05 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 40.909 | info       | 77.262 |\n",
            "Fold 3: AP=58.05, AP50=91.51, AP75=63.24\n",
            "Fold 4 / 5\n",
            "[03/10 04:01:06 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [03/10 04:01:06 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:01:06 d2.data.datasets.coco]: Loaded 80 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train_fold3.json\n",
            "[03/10 04:01:06 d2.data.build]: Removed 0 images with no usable annotations. 80 images left.\n",
            "[03/10 04:01:06 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|\n",
            "| department | 3098         |    info    | 150          |\n",
            "|            |              |            |              |\n",
            "|   total    | 3248         |            |              |\n",
            "[03/10 04:01:06 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[03/10 04:01:06 d2.data.build]: Using training sampler TrainingSampler\n",
            "[03/10 04:01:06 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:01:06 d2.data.common]: Serializing 80 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:01:06 d2.data.common]: Serialized dataset takes 0.41 MiB\n",
            "[03/10 04:01:06 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [03/10 04:01:06 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[03/10 04:01:06 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/10 04:01:06 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[03/10 04:01:10 d2.utils.events]:  eta: 0:01:30  iter: 19  total_loss: 5.308  loss_cls: 0.8743  loss_box_reg: 0.481  loss_mask: 0.6841  loss_rpn_cls: 3.043  loss_rpn_loc: 0.3688    time: 0.1928  last_time: 0.1727  data_time: 0.0191  last_data_time: 0.0024   lr: 1.5585e-05  max_mem: 4314M\n",
            "[03/10 04:01:14 d2.utils.events]:  eta: 0:01:29  iter: 39  total_loss: 2.778  loss_cls: 0.8157  loss_box_reg: 0.6799  loss_mask: 0.6386  loss_rpn_cls: 0.2907  loss_rpn_loc: 0.3193    time: 0.1952  last_time: 0.2166  data_time: 0.0025  last_data_time: 0.0026   lr: 3.1569e-05  max_mem: 4314M\n",
            "[03/10 04:01:18 d2.utils.events]:  eta: 0:01:25  iter: 59  total_loss: 2.474  loss_cls: 0.6824  loss_box_reg: 0.6282  loss_mask: 0.5674  loss_rpn_cls: 0.1656  loss_rpn_loc: 0.3173    time: 0.1947  last_time: 0.2273  data_time: 0.0024  last_data_time: 0.0024   lr: 4.7553e-05  max_mem: 4314M\n",
            "[03/10 04:01:22 d2.utils.events]:  eta: 0:01:21  iter: 79  total_loss: 1.975  loss_cls: 0.5543  loss_box_reg: 0.6318  loss_mask: 0.4513  loss_rpn_cls: 0.08243  loss_rpn_loc: 0.182    time: 0.1975  last_time: 0.2264  data_time: 0.0025  last_data_time: 0.0025   lr: 6.3537e-05  max_mem: 4314M\n",
            "[03/10 04:01:26 d2.utils.events]:  eta: 0:01:18  iter: 99  total_loss: 1.86  loss_cls: 0.4799  loss_box_reg: 0.6342  loss_mask: 0.3522  loss_rpn_cls: 0.114  loss_rpn_loc: 0.2082    time: 0.1984  last_time: 0.2024  data_time: 0.0025  last_data_time: 0.0028   lr: 7.9521e-05  max_mem: 4314M\n",
            "[03/10 04:01:30 d2.utils.events]:  eta: 0:01:14  iter: 119  total_loss: 1.821  loss_cls: 0.4223  loss_box_reg: 0.7002  loss_mask: 0.3301  loss_rpn_cls: 0.09353  loss_rpn_loc: 0.1906    time: 0.1990  last_time: 0.1906  data_time: 0.0025  last_data_time: 0.0023   lr: 9.5505e-05  max_mem: 4314M\n",
            "[03/10 04:01:34 d2.utils.events]:  eta: 0:01:10  iter: 139  total_loss: 1.617  loss_cls: 0.3608  loss_box_reg: 0.6901  loss_mask: 0.3123  loss_rpn_cls: 0.06087  loss_rpn_loc: 0.1596    time: 0.1984  last_time: 0.2167  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00011149  max_mem: 4314M\n",
            "[03/10 04:01:38 d2.utils.events]:  eta: 0:01:06  iter: 159  total_loss: 1.553  loss_cls: 0.3475  loss_box_reg: 0.645  loss_mask: 0.3315  loss_rpn_cls: 0.04857  loss_rpn_loc: 0.1588    time: 0.1983  last_time: 0.1966  data_time: 0.0026  last_data_time: 0.0028   lr: 0.00012747  max_mem: 4314M\n",
            "[03/10 04:01:42 d2.utils.events]:  eta: 0:01:02  iter: 179  total_loss: 1.642  loss_cls: 0.3199  loss_box_reg: 0.6628  loss_mask: 0.3287  loss_rpn_cls: 0.05138  loss_rpn_loc: 0.2049    time: 0.1984  last_time: 0.1563  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00014346  max_mem: 4314M\n",
            "[03/10 04:01:46 d2.utils.events]:  eta: 0:00:58  iter: 199  total_loss: 1.472  loss_cls: 0.3112  loss_box_reg: 0.6128  loss_mask: 0.2792  loss_rpn_cls: 0.05248  loss_rpn_loc: 0.1986    time: 0.1984  last_time: 0.1569  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00015944  max_mem: 4314M\n",
            "[03/10 04:01:50 d2.utils.events]:  eta: 0:00:55  iter: 219  total_loss: 1.338  loss_cls: 0.2738  loss_box_reg: 0.5985  loss_mask: 0.2561  loss_rpn_cls: 0.0489  loss_rpn_loc: 0.1696    time: 0.1989  last_time: 0.2109  data_time: 0.0026  last_data_time: 0.0024   lr: 0.00017542  max_mem: 4314M\n",
            "[03/10 04:01:54 d2.utils.events]:  eta: 0:00:51  iter: 239  total_loss: 1.236  loss_cls: 0.2778  loss_box_reg: 0.5314  loss_mask: 0.2619  loss_rpn_cls: 0.04542  loss_rpn_loc: 0.1533    time: 0.1991  last_time: 0.1786  data_time: 0.0026  last_data_time: 0.0024   lr: 0.00019141  max_mem: 4314M\n",
            "[03/10 04:01:58 d2.utils.events]:  eta: 0:00:47  iter: 259  total_loss: 1.288  loss_cls: 0.2529  loss_box_reg: 0.5446  loss_mask: 0.2197  loss_rpn_cls: 0.03652  loss_rpn_loc: 0.1697    time: 0.1995  last_time: 0.2191  data_time: 0.0026  last_data_time: 0.0023   lr: 0.00020739  max_mem: 4314M\n",
            "[03/10 04:02:02 d2.utils.events]:  eta: 0:00:43  iter: 279  total_loss: 1.201  loss_cls: 0.226  loss_box_reg: 0.5312  loss_mask: 0.225  loss_rpn_cls: 0.03159  loss_rpn_loc: 0.1752    time: 0.1997  last_time: 0.2412  data_time: 0.0026  last_data_time: 0.0023   lr: 0.00022338  max_mem: 4314M\n",
            "[03/10 04:02:06 d2.utils.events]:  eta: 0:00:39  iter: 299  total_loss: 1.202  loss_cls: 0.2219  loss_box_reg: 0.5132  loss_mask: 0.2147  loss_rpn_cls: 0.04007  loss_rpn_loc: 0.1794    time: 0.1995  last_time: 0.2179  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00023936  max_mem: 4314M\n",
            "[03/10 04:02:10 d2.utils.events]:  eta: 0:00:35  iter: 319  total_loss: 1.052  loss_cls: 0.2312  loss_box_reg: 0.4475  loss_mask: 0.2119  loss_rpn_cls: 0.02439  loss_rpn_loc: 0.1556    time: 0.1995  last_time: 0.1911  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00025534  max_mem: 4314M\n",
            "[03/10 04:02:14 d2.utils.events]:  eta: 0:00:31  iter: 339  total_loss: 1.036  loss_cls: 0.1906  loss_box_reg: 0.4493  loss_mask: 0.1913  loss_rpn_cls: 0.02074  loss_rpn_loc: 0.147    time: 0.1994  last_time: 0.2105  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00027133  max_mem: 4314M\n",
            "[03/10 04:02:18 d2.utils.events]:  eta: 0:00:28  iter: 359  total_loss: 1.103  loss_cls: 0.2104  loss_box_reg: 0.4466  loss_mask: 0.1971  loss_rpn_cls: 0.02626  loss_rpn_loc: 0.1887    time: 0.1998  last_time: 0.2147  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00028731  max_mem: 4314M\n",
            "[03/10 04:02:23 d2.utils.events]:  eta: 0:00:24  iter: 379  total_loss: 0.9331  loss_cls: 0.1823  loss_box_reg: 0.3741  loss_mask: 0.1854  loss_rpn_cls: 0.02783  loss_rpn_loc: 0.1397    time: 0.2002  last_time: 0.2627  data_time: 0.0025  last_data_time: 0.0024   lr: 0.0003033  max_mem: 4314M\n",
            "[03/10 04:02:27 d2.utils.events]:  eta: 0:00:20  iter: 399  total_loss: 1.188  loss_cls: 0.1989  loss_box_reg: 0.4452  loss_mask: 0.2004  loss_rpn_cls: 0.04257  loss_rpn_loc: 0.2032    time: 0.2003  last_time: 0.1714  data_time: 0.0025  last_data_time: 0.0023   lr: 0.00031928  max_mem: 4314M\n",
            "[03/10 04:02:31 d2.utils.events]:  eta: 0:00:16  iter: 419  total_loss: 1.025  loss_cls: 0.1903  loss_box_reg: 0.4093  loss_mask: 0.1968  loss_rpn_cls: 0.03687  loss_rpn_loc: 0.1832    time: 0.2004  last_time: 0.1842  data_time: 0.0025  last_data_time: 0.0026   lr: 0.00033526  max_mem: 4314M\n",
            "[03/10 04:02:35 d2.utils.events]:  eta: 0:00:12  iter: 439  total_loss: 0.9178  loss_cls: 0.2393  loss_box_reg: 0.3862  loss_mask: 0.1646  loss_rpn_cls: 0.03232  loss_rpn_loc: 0.1884    time: 0.2008  last_time: 0.2353  data_time: 0.0026  last_data_time: 0.0025   lr: 0.00035125  max_mem: 4314M\n",
            "[03/10 04:02:39 d2.utils.events]:  eta: 0:00:08  iter: 459  total_loss: 1.051  loss_cls: 0.2042  loss_box_reg: 0.38  loss_mask: 0.1906  loss_rpn_cls: 0.03196  loss_rpn_loc: 0.2093    time: 0.2003  last_time: 0.2135  data_time: 0.0026  last_data_time: 0.0021   lr: 0.00036723  max_mem: 4314M\n",
            "[03/10 04:02:43 d2.utils.events]:  eta: 0:00:04  iter: 479  total_loss: 0.8788  loss_cls: 0.1479  loss_box_reg: 0.3562  loss_mask: 0.1623  loss_rpn_cls: 0.0258  loss_rpn_loc: 0.1743    time: 0.2005  last_time: 0.2211  data_time: 0.0024  last_data_time: 0.0024   lr: 0.00038322  max_mem: 4314M\n",
            "[03/10 04:02:48 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.9943  loss_cls: 0.2121  loss_box_reg: 0.395  loss_mask: 0.1686  loss_rpn_cls: 0.03494  loss_rpn_loc: 0.1901    time: 0.2006  last_time: 0.2118  data_time: 0.0025  last_data_time: 0.0025   lr: 0.0003992  max_mem: 4314M\n",
            "[03/10 04:02:49 d2.engine.hooks]: Overall training speed: 498 iterations in 0:01:39 (0.2006 s / it)\n",
            "[03/10 04:02:49 d2.engine.hooks]: Total training time: 0:01:41 (0:00:01 on hooks)\n",
            "WARNING [03/10 04:02:49 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:02:49 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold3.json\n",
            "[03/10 04:02:49 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|\n",
            "| department | 748          |    info    | 44           |\n",
            "|            |              |            |              |\n",
            "|   total    | 792          |            |              |\n",
            "[03/10 04:02:49 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:02:49 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:02:49 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:02:49 d2.data.common]: Serialized dataset takes 0.11 MiB\n",
            "WARNING [03/10 04:02:49 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "WARNING [03/10 04:02:49 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "WARNING [03/10 04:02:49 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:02:49 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold3.json\n",
            "[03/10 04:02:49 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:02:49 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:02:49 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:02:49 d2.data.common]: Serialized dataset takes 0.11 MiB\n",
            "[03/10 04:02:49 d2.evaluation.evaluator]: Start inference on 20 batches\n",
            "[03/10 04:02:57 d2.evaluation.evaluator]: Inference done 11/20. Dataloading: 0.0013 s/iter. Inference: 0.2038 s/iter. Eval: 0.7982 s/iter. Total: 1.0032 s/iter. ETA=0:00:09\n",
            "[03/10 04:03:03 d2.evaluation.evaluator]: Inference done 19/20. Dataloading: 0.0015 s/iter. Inference: 0.1864 s/iter. Eval: 0.6633 s/iter. Total: 0.8514 s/iter. ETA=0:00:00\n",
            "[03/10 04:03:04 d2.evaluation.evaluator]: Total inference time: 0:00:12.773263 (0.851551 s / iter per device, on 1 devices)\n",
            "[03/10 04:03:04 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.186178 s / iter per device, on 1 devices)\n",
            "[03/10 04:03:04 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[03/10 04:03:04 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n",
            "[03/10 04:03:04 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:03:04 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[03/10 04:03:04 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n",
            "[03/10 04:03:04 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:03:04 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.689\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.973\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.785\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.613\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.695\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.161\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.497\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.742\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.676\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.746\n",
            "[03/10 04:03:04 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 68.872 | 97.316 | 78.453 |  nan  | 61.331 | 69.499 |\n",
            "[03/10 04:03:04 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:03:04 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 61.533 | info       | 76.211 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:03:04 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[03/10 04:03:04 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.06 seconds.\n",
            "[03/10 04:03:04 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:03:04 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.709\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.973\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.842\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.639\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.717\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.763\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761\n",
            "[03/10 04:03:04 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 70.925 | 97.311 | 84.201 |  nan  | 63.914 | 71.654 |\n",
            "[03/10 04:03:04 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:03:04 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 64.160 | info       | 77.690 |\n",
            "Fold 4: AP=68.87, AP50=97.32, AP75=78.45\n",
            "Fold 5 / 5\n",
            "[03/10 04:03:05 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [03/10 04:03:05 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:03:05 d2.data.datasets.coco]: Loaded 80 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train_fold4.json\n",
            "[03/10 04:03:05 d2.data.build]: Removed 0 images with no usable annotations. 80 images left.\n",
            "[03/10 04:03:05 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|\n",
            "| department | 3001         |    info    | 156          |\n",
            "|            |              |            |              |\n",
            "|   total    | 3157         |            |              |\n",
            "[03/10 04:03:05 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[03/10 04:03:05 d2.data.build]: Using training sampler TrainingSampler\n",
            "[03/10 04:03:05 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:03:05 d2.data.common]: Serializing 80 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:03:05 d2.data.common]: Serialized dataset takes 0.40 MiB\n",
            "[03/10 04:03:05 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [03/10 04:03:05 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[03/10 04:03:05 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/10 04:03:05 d2.engine.train_loop]: Starting training from iteration 0\n",
            "[03/10 04:03:10 d2.utils.events]:  eta: 0:01:40  iter: 19  total_loss: 5.874  loss_cls: 0.8572  loss_box_reg: 0.5211  loss_mask: 0.687  loss_rpn_cls: 3.327  loss_rpn_loc: 0.4621    time: 0.2074  last_time: 0.2403  data_time: 0.0171  last_data_time: 0.0025   lr: 1.5585e-05  max_mem: 4326M\n",
            "[03/10 04:03:14 d2.utils.events]:  eta: 0:01:36  iter: 39  total_loss: 2.715  loss_cls: 0.7883  loss_box_reg: 0.666  loss_mask: 0.6432  loss_rpn_cls: 0.3204  loss_rpn_loc: 0.2898    time: 0.2038  last_time: 0.2111  data_time: 0.0025  last_data_time: 0.0024   lr: 3.1569e-05  max_mem: 4326M\n",
            "[03/10 04:03:18 d2.utils.events]:  eta: 0:01:31  iter: 59  total_loss: 2.292  loss_cls: 0.6694  loss_box_reg: 0.6206  loss_mask: 0.5694  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.2244    time: 0.2036  last_time: 0.1755  data_time: 0.0025  last_data_time: 0.0028   lr: 4.7553e-05  max_mem: 4326M\n",
            "[03/10 04:03:22 d2.utils.events]:  eta: 0:01:23  iter: 79  total_loss: 1.998  loss_cls: 0.5485  loss_box_reg: 0.6306  loss_mask: 0.4678  loss_rpn_cls: 0.08259  loss_rpn_loc: 0.1938    time: 0.2015  last_time: 0.1872  data_time: 0.0026  last_data_time: 0.0024   lr: 6.3537e-05  max_mem: 4326M\n",
            "[03/10 04:03:26 d2.utils.events]:  eta: 0:01:19  iter: 99  total_loss: 1.979  loss_cls: 0.4942  loss_box_reg: 0.7053  loss_mask: 0.3903  loss_rpn_cls: 0.07254  loss_rpn_loc: 0.1936    time: 0.2018  last_time: 0.1885  data_time: 0.0026  last_data_time: 0.0029   lr: 7.9521e-05  max_mem: 4326M\n",
            "[03/10 04:03:30 d2.utils.events]:  eta: 0:01:15  iter: 119  total_loss: 1.771  loss_cls: 0.4401  loss_box_reg: 0.6352  loss_mask: 0.3614  loss_rpn_cls: 0.0697  loss_rpn_loc: 0.1971    time: 0.2023  last_time: 0.2226  data_time: 0.0025  last_data_time: 0.0028   lr: 9.5505e-05  max_mem: 4326M\n",
            "[03/10 04:03:34 d2.utils.events]:  eta: 0:01:11  iter: 139  total_loss: 1.682  loss_cls: 0.3918  loss_box_reg: 0.674  loss_mask: 0.3276  loss_rpn_cls: 0.07412  loss_rpn_loc: 0.1939    time: 0.2020  last_time: 0.1865  data_time: 0.0025  last_data_time: 0.0023   lr: 0.00011149  max_mem: 4326M\n",
            "[03/10 04:03:38 d2.utils.events]:  eta: 0:01:07  iter: 159  total_loss: 1.627  loss_cls: 0.374  loss_box_reg: 0.6804  loss_mask: 0.3221  loss_rpn_cls: 0.07444  loss_rpn_loc: 0.2077    time: 0.2010  last_time: 0.1736  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00012747  max_mem: 4326M\n",
            "[03/10 04:03:42 d2.utils.events]:  eta: 0:01:02  iter: 179  total_loss: 1.55  loss_cls: 0.3261  loss_box_reg: 0.6589  loss_mask: 0.3181  loss_rpn_cls: 0.06139  loss_rpn_loc: 0.1668    time: 0.2002  last_time: 0.2399  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00014346  max_mem: 4326M\n",
            "[03/10 04:03:46 d2.utils.events]:  eta: 0:00:58  iter: 199  total_loss: 1.505  loss_cls: 0.3297  loss_box_reg: 0.6324  loss_mask: 0.2755  loss_rpn_cls: 0.04753  loss_rpn_loc: 0.186    time: 0.1995  last_time: 0.2078  data_time: 0.0026  last_data_time: 0.0023   lr: 0.00015944  max_mem: 4326M\n",
            "[03/10 04:03:50 d2.utils.events]:  eta: 0:00:55  iter: 219  total_loss: 1.552  loss_cls: 0.3238  loss_box_reg: 0.6339  loss_mask: 0.2946  loss_rpn_cls: 0.05434  loss_rpn_loc: 0.186    time: 0.2004  last_time: 0.2466  data_time: 0.0026  last_data_time: 0.0027   lr: 0.00017542  max_mem: 4326M\n",
            "[03/10 04:03:54 d2.utils.events]:  eta: 0:00:51  iter: 239  total_loss: 1.368  loss_cls: 0.2862  loss_box_reg: 0.5795  loss_mask: 0.2543  loss_rpn_cls: 0.04412  loss_rpn_loc: 0.1681    time: 0.2006  last_time: 0.2434  data_time: 0.0026  last_data_time: 0.0023   lr: 0.00019141  max_mem: 4326M\n",
            "[03/10 04:03:58 d2.utils.events]:  eta: 0:00:47  iter: 259  total_loss: 1.269  loss_cls: 0.2748  loss_box_reg: 0.533  loss_mask: 0.2394  loss_rpn_cls: 0.04233  loss_rpn_loc: 0.1968    time: 0.2002  last_time: 0.1930  data_time: 0.0025  last_data_time: 0.0023   lr: 0.00020739  max_mem: 4326M\n",
            "[03/10 04:04:02 d2.utils.events]:  eta: 0:00:43  iter: 279  total_loss: 1.339  loss_cls: 0.2689  loss_box_reg: 0.5715  loss_mask: 0.235  loss_rpn_cls: 0.04674  loss_rpn_loc: 0.1788    time: 0.1997  last_time: 0.1957  data_time: 0.0025  last_data_time: 0.0023   lr: 0.00022338  max_mem: 4326M\n",
            "[03/10 04:04:06 d2.utils.events]:  eta: 0:00:39  iter: 299  total_loss: 1.263  loss_cls: 0.2416  loss_box_reg: 0.5613  loss_mask: 0.2378  loss_rpn_cls: 0.02994  loss_rpn_loc: 0.1782    time: 0.1992  last_time: 0.1663  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00023936  max_mem: 4326M\n",
            "[03/10 04:04:10 d2.utils.events]:  eta: 0:00:35  iter: 319  total_loss: 1.074  loss_cls: 0.2207  loss_box_reg: 0.4886  loss_mask: 0.2006  loss_rpn_cls: 0.03191  loss_rpn_loc: 0.1592    time: 0.1995  last_time: 0.2005  data_time: 0.0026  last_data_time: 0.0029   lr: 0.00025534  max_mem: 4326M\n",
            "[03/10 04:04:14 d2.utils.events]:  eta: 0:00:31  iter: 339  total_loss: 1.122  loss_cls: 0.2374  loss_box_reg: 0.4532  loss_mask: 0.1879  loss_rpn_cls: 0.01815  loss_rpn_loc: 0.1687    time: 0.1994  last_time: 0.2148  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00027133  max_mem: 4326M\n",
            "[03/10 04:04:18 d2.utils.events]:  eta: 0:00:27  iter: 359  total_loss: 1.144  loss_cls: 0.2412  loss_box_reg: 0.465  loss_mask: 0.2102  loss_rpn_cls: 0.02252  loss_rpn_loc: 0.1842    time: 0.1997  last_time: 0.2176  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00028731  max_mem: 4326M\n",
            "[03/10 04:04:22 d2.utils.events]:  eta: 0:00:23  iter: 379  total_loss: 1.01  loss_cls: 0.202  loss_box_reg: 0.4389  loss_mask: 0.181  loss_rpn_cls: 0.02282  loss_rpn_loc: 0.1671    time: 0.1995  last_time: 0.2204  data_time: 0.0025  last_data_time: 0.0025   lr: 0.0003033  max_mem: 4326M\n",
            "[03/10 04:04:26 d2.utils.events]:  eta: 0:00:19  iter: 399  total_loss: 1.026  loss_cls: 0.2197  loss_box_reg: 0.4251  loss_mask: 0.1934  loss_rpn_cls: 0.02704  loss_rpn_loc: 0.1798    time: 0.1994  last_time: 0.1868  data_time: 0.0024  last_data_time: 0.0028   lr: 0.00031928  max_mem: 4326M\n",
            "[03/10 04:04:30 d2.utils.events]:  eta: 0:00:15  iter: 419  total_loss: 0.9859  loss_cls: 0.1994  loss_box_reg: 0.3972  loss_mask: 0.1939  loss_rpn_cls: 0.01577  loss_rpn_loc: 0.1767    time: 0.1995  last_time: 0.1727  data_time: 0.0026  last_data_time: 0.0026   lr: 0.00033526  max_mem: 4326M\n",
            "[03/10 04:04:34 d2.utils.events]:  eta: 0:00:11  iter: 439  total_loss: 0.913  loss_cls: 0.1908  loss_box_reg: 0.3851  loss_mask: 0.1895  loss_rpn_cls: 0.01963  loss_rpn_loc: 0.1569    time: 0.1996  last_time: 0.2161  data_time: 0.0025  last_data_time: 0.0022   lr: 0.00035125  max_mem: 4326M\n",
            "[03/10 04:04:38 d2.utils.events]:  eta: 0:00:07  iter: 459  total_loss: 1.025  loss_cls: 0.1813  loss_box_reg: 0.3783  loss_mask: 0.1749  loss_rpn_cls: 0.02899  loss_rpn_loc: 0.1873    time: 0.1997  last_time: 0.2182  data_time: 0.0025  last_data_time: 0.0028   lr: 0.00036723  max_mem: 4326M\n",
            "[03/10 04:04:42 d2.utils.events]:  eta: 0:00:03  iter: 479  total_loss: 0.9046  loss_cls: 0.1872  loss_box_reg: 0.3579  loss_mask: 0.1781  loss_rpn_cls: 0.02531  loss_rpn_loc: 0.1696    time: 0.1999  last_time: 0.1849  data_time: 0.0025  last_data_time: 0.0027   lr: 0.00038322  max_mem: 4326M\n",
            "[03/10 04:04:47 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.9467  loss_cls: 0.1755  loss_box_reg: 0.37  loss_mask: 0.192  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.16    time: 0.2001  last_time: 0.1737  data_time: 0.0025  last_data_time: 0.0025   lr: 0.0003992  max_mem: 4326M\n",
            "[03/10 04:04:48 d2.engine.hooks]: Overall training speed: 498 iterations in 0:01:39 (0.2001 s / it)\n",
            "[03/10 04:04:48 d2.engine.hooks]: Total training time: 0:01:41 (0:00:01 on hooks)\n",
            "WARNING [03/10 04:04:48 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:04:48 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold4.json\n",
            "[03/10 04:04:48 d2.data.build]: Distribution of instances among all 2 categories:\n",
            "|  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|\n",
            "| department | 845          |    info    | 38           |\n",
            "|            |              |            |              |\n",
            "|   total    | 883          |            |              |\n",
            "[03/10 04:04:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:04:48 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:04:48 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:04:48 d2.data.common]: Serialized dataset takes 0.12 MiB\n",
            "WARNING [03/10 04:04:48 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
            "WARNING [03/10 04:04:48 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "WARNING [03/10 04:04:48 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[03/10 04:04:48 d2.data.datasets.coco]: Loaded 20 images in COCO format from /content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold4.json\n",
            "[03/10 04:04:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[03/10 04:04:48 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/10 04:04:48 d2.data.common]: Serializing 20 elements to byte tensors and concatenating them all ...\n",
            "[03/10 04:04:48 d2.data.common]: Serialized dataset takes 0.12 MiB\n",
            "[03/10 04:04:48 d2.evaluation.evaluator]: Start inference on 20 batches\n",
            "[03/10 04:04:56 d2.evaluation.evaluator]: Inference done 11/20. Dataloading: 0.0013 s/iter. Inference: 0.1675 s/iter. Eval: 0.4697 s/iter. Total: 0.6385 s/iter. ETA=0:00:05\n",
            "[03/10 04:05:01 d2.evaluation.evaluator]: Inference done 17/20. Dataloading: 0.0015 s/iter. Inference: 0.1775 s/iter. Eval: 0.5682 s/iter. Total: 0.7473 s/iter. ETA=0:00:02\n",
            "[03/10 04:05:04 d2.evaluation.evaluator]: Total inference time: 0:00:11.745773 (0.783052 s / iter per device, on 1 devices)\n",
            "[03/10 04:05:04 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.180695 s / iter per device, on 1 devices)\n",
            "[03/10 04:05:04 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[03/10 04:05:04 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n",
            "[03/10 04:05:04 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:05:04 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[03/10 04:05:04 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.03 seconds.\n",
            "[03/10 04:05:04 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:05:04 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.714\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.976\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.860\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.684\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.703\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.172\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.766\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758\n",
            "[03/10 04:05:04 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 71.384 | 97.629 | 85.988 |  nan  | 68.372 | 70.254 |\n",
            "[03/10 04:05:04 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:05:04 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 66.667 | info       | 76.101 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[03/10 04:05:04 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[03/10 04:05:04 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.07 seconds.\n",
            "[03/10 04:05:04 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[03/10 04:05:04 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.976\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.895\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.696\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.761\n",
            "[03/10 04:05:04 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 73.324 | 97.559 | 89.469 |  nan  | 69.642 | 71.815 |\n",
            "[03/10 04:05:04 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
            "[03/10 04:05:04 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|\n",
            "| department | 67.559 | info       | 79.088 |\n",
            "Fold 5: AP=71.38, AP50=97.63, AP75=85.99\n",
            "\n",
            "Final Cross-validation Results:\n",
            "Mean AP: 64.17\n",
            "Mean AP50: 94.19\n",
            "Mean AP75: 74.26\n"
          ]
        }
      ],
      "source": [
        "# path\n",
        "path = \"/content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train\"\n",
        "path_coco = \"/content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/Organization_annotation.json\"\n",
        "\n",
        "# load data\n",
        "with open(path_coco) as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "annotations = coco_data[\"annotations\"]\n",
        "images = coco_data[\"images\"]\n",
        "\n",
        "# setting for K-fold cross validation\n",
        "K = 5  # num of fold\n",
        "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
        "\n",
        "# Cross validation\n",
        "ap_scores = []\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(images)):\n",
        "    print(f\"Fold {fold + 1} / {K}\")\n",
        "\n",
        "    # split data (train and validation)\n",
        "    train_images = [images[i] for i in train_idx]\n",
        "    val_images = [images[i] for i in val_idx]\n",
        "\n",
        "    train_ids = {img[\"id\"] for img in train_images}\n",
        "    train_annotations = [ann for ann in annotations if ann[\"image_id\"] in train_ids]\n",
        "\n",
        "    val_ids = {img[\"id\"] for img in val_images}\n",
        "    val_annotations = [ann for ann in annotations if ann[\"image_id\"] in val_ids]\n",
        "\n",
        "    train_coco = {\"images\": train_images, \"annotations\": train_annotations, \"categories\": coco_data[\"categories\"]}\n",
        "    val_coco = {\"images\": val_images, \"annotations\": val_annotations, \"categories\": coco_data[\"categories\"]}\n",
        "\n",
        "    # annotation paths\n",
        "    train_coco_path = f\"/content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/train_fold{fold}.json\"\n",
        "    val_coco_path = f\"/content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning/val_fold{fold}.json\"\n",
        "\n",
        "    with open(train_coco_path, \"w\") as f:\n",
        "        json.dump(train_coco, f)\n",
        "    with open(val_coco_path, \"w\") as f:\n",
        "        json.dump(val_coco, f)\n",
        "\n",
        "    # Detectron2\n",
        "    register_coco_instances(f\"org_train_{fold}\", {}, train_coco_path, path)\n",
        "    register_coco_instances(f\"org_val_{fold}\", {}, val_coco_path, path)\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "    cfg.DATASETS.TRAIN = (f\"org_train_{fold}\",)\n",
        "    cfg.DATASETS.TEST = (f\"org_val_{fold}\",)\n",
        "    cfg.DATALOADER.NUM_WORKERS = 2\n",
        "    cfg.SOLVER.IMS_PER_BATCH = 1\n",
        "    cfg.SOLVER.BASE_LR = 0.0004\n",
        "    cfg.SOLVER.MAX_ITER = 500\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "\n",
        "    # train\n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    trainer = DefaultTrainer(cfg)\n",
        "    trainer.resume_or_load(resume=False)\n",
        "    trainer.train()\n",
        "\n",
        "    # evaluation\n",
        "    evaluator = COCOEvaluator(f\"org_val_{fold}\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
        "    val_loader = build_detection_test_loader(cfg, f\"org_val_{fold}\")\n",
        "    eval_results = inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "\n",
        "    # AP\n",
        "    ap = eval_results[\"bbox\"][\"AP\"]      # IoU 50-95: mAP\n",
        "    ap50 = eval_results[\"bbox\"][\"AP50\"]  # IoU 50: AP\n",
        "    ap75 = eval_results[\"bbox\"][\"AP75\"]  # IoU 75: AP\n",
        "\n",
        "    print(f\"Fold {fold + 1}: AP={ap:.2f}, AP50={ap50:.2f}, AP75={ap75:.2f}\")\n",
        "    ap_scores.append((ap, ap50, ap75))\n",
        "\n",
        "# results\n",
        "mean_ap = np.mean([score[0] for score in ap_scores])\n",
        "mean_ap50 = np.mean([score[1] for score in ap_scores])\n",
        "mean_ap75 = np.mean([score[2] for score in ap_scores])\n",
        "\n",
        "print(f\"\\nFinal Cross-validation Results:\")\n",
        "print(f\"Mean AP: {mean_ap:.2f}\")\n",
        "print(f\"Mean AP50: {mean_ap50:.2f}\")\n",
        "print(f\"Mean AP75: {mean_ap75:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}