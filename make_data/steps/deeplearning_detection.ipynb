{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntr3kXD8Kg3o"
      },
      "source": [
        "### Please run with Google Colab with Good GPU\n",
        "<a href=\"https://colab.research.google.com/github/wakachii/SI-Org-chart/blob/main/make_data/steps/deeplearning_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P3gTVMDKg3q",
        "outputId": "05ffd2d9-9f7b-4a0a-9d3f-3119716ef5ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-gc226ei5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-gc226ei5\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 9604f5995cc628619f0e4fd913453b4d7d61db3f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.10.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.5.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (4.67.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.18.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (25.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (8.1.8)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (4.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Detectron2 has not released pre-built binaries for the latest pytorch (https://github.com/facebookresearch/detectron2/issues/4053)\n",
        "# so we install from source instead. This takes a few minutes.\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDqe8fW1Kg3q",
        "outputId": "b4248e0e-d2fd-45d4-862c-9ec856505be8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import cv2 as cv2\n",
        "import json\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "import matplotlib.pyplot as plt\n",
        "import detectron2\n",
        "from tqdm import tqdm\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_FTuJydKg3r",
        "outputId": "01e029d3-6d3d-4122-f391-2f117d5fb185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02/16 16:56:44 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "WARNING [02/16 16:56:45 d2.data.datasets.coco]: \n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "[02/16 16:56:45 d2.data.datasets.coco]: Loaded 8 images in COCO format from /content/drive/MyDrive/scan_org_charts/learning/Org_chart-1.json\n",
            "[02/16 16:56:45 d2.data.build]: Removed 0 images with no usable annotations. 8 images left.\n",
            "[02/16 16:56:45 d2.data.build]: Distribution of instances among all 1 categories:\n",
            "|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "| department | 196          |\n",
            "|            |              |\n",
            "[02/16 16:56:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[02/16 16:56:45 d2.data.build]: Using training sampler TrainingSampler\n",
            "[02/16 16:56:45 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[02/16 16:56:45 d2.data.common]: Serializing 8 elements to byte tensors and concatenating them all ...\n",
            "[02/16 16:56:45 d2.data.common]: Serialized dataset takes 0.03 MiB\n",
            "[02/16 16:56:45 d2.data.build]: Making batched data loader with batch_size=1\n",
            "WARNING [02/16 16:56:45 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "[02/16 16:56:45 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model_final_f10217.pkl: 178MB [00:02, 77.8MB/s]                           \n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n",
            "roi_heads.mask_head.predictor.{bias, weight}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02/16 16:56:48 d2.engine.train_loop]: Starting training from iteration 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[02/16 16:57:02 d2.utils.events]:  eta: 0:01:59  iter: 19  total_loss: 5.225  loss_cls: 0.6917  loss_box_reg: 0.7193  loss_mask: 0.6931  loss_rpn_cls: 2.864  loss_rpn_loc: 0.3243    time: 0.2837  last_time: 0.2103  data_time: 0.1086  last_data_time: 0.0028   lr: 1.5585e-05  max_mem: 1529M\n",
            "[02/16 16:57:11 d2.utils.events]:  eta: 0:01:45  iter: 39  total_loss: 2.439  loss_cls: 0.6156  loss_box_reg: 0.8183  loss_mask: 0.635  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.2125    time: 0.2504  last_time: 0.1774  data_time: 0.0035  last_data_time: 0.0028   lr: 3.1569e-05  max_mem: 1561M\n",
            "[02/16 16:57:16 d2.utils.events]:  eta: 0:01:38  iter: 59  total_loss: 2.112  loss_cls: 0.5608  loss_box_reg: 0.8197  loss_mask: 0.5042  loss_rpn_cls: 0.04225  loss_rpn_loc: 0.18    time: 0.2401  last_time: 0.2632  data_time: 0.0034  last_data_time: 0.0028   lr: 4.7553e-05  max_mem: 1561M\n",
            "[02/16 16:57:21 d2.utils.events]:  eta: 0:01:37  iter: 79  total_loss: 1.977  loss_cls: 0.5169  loss_box_reg: 0.807  loss_mask: 0.3863  loss_rpn_cls: 0.04576  loss_rpn_loc: 0.1708    time: 0.2463  last_time: 0.2300  data_time: 0.0076  last_data_time: 0.0027   lr: 6.3537e-05  max_mem: 1561M\n",
            "[02/16 16:57:25 d2.utils.events]:  eta: 0:01:32  iter: 99  total_loss: 1.815  loss_cls: 0.4727  loss_box_reg: 0.8232  loss_mask: 0.3123  loss_rpn_cls: 0.03707  loss_rpn_loc: 0.1579    time: 0.2411  last_time: 0.2166  data_time: 0.0038  last_data_time: 0.0030   lr: 7.9521e-05  max_mem: 1561M\n",
            "[02/16 16:57:30 d2.utils.events]:  eta: 0:01:27  iter: 119  total_loss: 1.622  loss_cls: 0.4036  loss_box_reg: 0.762  loss_mask: 0.2867  loss_rpn_cls: 0.03909  loss_rpn_loc: 0.1355    time: 0.2385  last_time: 0.1865  data_time: 0.0041  last_data_time: 0.0024   lr: 9.5505e-05  max_mem: 1561M\n",
            "[02/16 16:57:35 d2.utils.events]:  eta: 0:01:24  iter: 139  total_loss: 1.529  loss_cls: 0.363  loss_box_reg: 0.7332  loss_mask: 0.2633  loss_rpn_cls: 0.01775  loss_rpn_loc: 0.1479    time: 0.2430  last_time: 0.1661  data_time: 0.0089  last_data_time: 0.0039   lr: 0.00011149  max_mem: 1562M\n",
            "[02/16 16:57:40 d2.utils.events]:  eta: 0:01:18  iter: 159  total_loss: 1.371  loss_cls: 0.3124  loss_box_reg: 0.681  loss_mask: 0.2322  loss_rpn_cls: 0.01878  loss_rpn_loc: 0.1252    time: 0.2406  last_time: 0.2140  data_time: 0.0039  last_data_time: 0.0030   lr: 0.00012747  max_mem: 1562M\n",
            "[02/16 16:57:45 d2.utils.events]:  eta: 0:01:14  iter: 179  total_loss: 1.23  loss_cls: 0.2585  loss_box_reg: 0.5998  loss_mask: 0.1968  loss_rpn_cls: 0.009946  loss_rpn_loc: 0.1195    time: 0.2408  last_time: 0.3110  data_time: 0.0059  last_data_time: 0.0242   lr: 0.00014346  max_mem: 1562M\n",
            "[02/16 16:57:50 d2.utils.events]:  eta: 0:01:10  iter: 199  total_loss: 1.055  loss_cls: 0.2459  loss_box_reg: 0.5055  loss_mask: 0.1767  loss_rpn_cls: 0.01947  loss_rpn_loc: 0.1234    time: 0.2416  last_time: 0.2256  data_time: 0.0099  last_data_time: 0.0027   lr: 0.00015944  max_mem: 1562M\n",
            "[02/16 16:57:54 d2.utils.events]:  eta: 0:01:04  iter: 219  total_loss: 0.9195  loss_cls: 0.2162  loss_box_reg: 0.4096  loss_mask: 0.1667  loss_rpn_cls: 0.01267  loss_rpn_loc: 0.1253    time: 0.2399  last_time: 0.2588  data_time: 0.0037  last_data_time: 0.0028   lr: 0.00017542  max_mem: 1562M\n",
            "[02/16 16:57:59 d2.utils.events]:  eta: 0:01:00  iter: 239  total_loss: 0.8506  loss_cls: 0.2061  loss_box_reg: 0.3565  loss_mask: 0.1521  loss_rpn_cls: 0.009074  loss_rpn_loc: 0.1259    time: 0.2408  last_time: 0.2414  data_time: 0.0049  last_data_time: 0.0129   lr: 0.00019141  max_mem: 1562M\n",
            "[02/16 16:58:04 d2.utils.events]:  eta: 0:00:56  iter: 259  total_loss: 0.8179  loss_cls: 0.1891  loss_box_reg: 0.3536  loss_mask: 0.1464  loss_rpn_cls: 0.006915  loss_rpn_loc: 0.1212    time: 0.2426  last_time: 0.1915  data_time: 0.0053  last_data_time: 0.0033   lr: 0.00020739  max_mem: 1562M\n",
            "[02/16 16:58:09 d2.utils.events]:  eta: 0:00:51  iter: 279  total_loss: 0.7183  loss_cls: 0.1614  loss_box_reg: 0.33  loss_mask: 0.1426  loss_rpn_cls: 0.005369  loss_rpn_loc: 0.1105    time: 0.2419  last_time: 0.1431  data_time: 0.0031  last_data_time: 0.0029   lr: 0.00022338  max_mem: 1562M\n",
            "[02/16 16:58:14 d2.utils.events]:  eta: 0:00:47  iter: 299  total_loss: 0.7354  loss_cls: 0.1418  loss_box_reg: 0.3336  loss_mask: 0.1497  loss_rpn_cls: 0.007632  loss_rpn_loc: 0.1265    time: 0.2433  last_time: 0.2543  data_time: 0.0077  last_data_time: 0.0030   lr: 0.00023936  max_mem: 1562M\n",
            "[02/16 16:58:19 d2.utils.events]:  eta: 0:00:42  iter: 319  total_loss: 0.7144  loss_cls: 0.1368  loss_box_reg: 0.29  loss_mask: 0.1418  loss_rpn_cls: 0.004285  loss_rpn_loc: 0.1125    time: 0.2430  last_time: 0.2289  data_time: 0.0047  last_data_time: 0.0031   lr: 0.00025534  max_mem: 1562M\n",
            "[02/16 16:58:24 d2.utils.events]:  eta: 0:00:37  iter: 339  total_loss: 0.6398  loss_cls: 0.1325  loss_box_reg: 0.2709  loss_mask: 0.1391  loss_rpn_cls: 0.005637  loss_rpn_loc: 0.1109    time: 0.2416  last_time: 0.2275  data_time: 0.0030  last_data_time: 0.0025   lr: 0.00027133  max_mem: 1562M\n",
            "[02/16 16:58:29 d2.utils.events]:  eta: 0:00:33  iter: 359  total_loss: 0.6662  loss_cls: 0.1675  loss_box_reg: 0.2607  loss_mask: 0.13  loss_rpn_cls: 0.006131  loss_rpn_loc: 0.1176    time: 0.2443  last_time: 0.2930  data_time: 0.0100  last_data_time: 0.0037   lr: 0.00028731  max_mem: 1562M\n",
            "[02/16 16:58:34 d2.utils.events]:  eta: 0:00:28  iter: 379  total_loss: 0.6205  loss_cls: 0.1377  loss_box_reg: 0.261  loss_mask: 0.1216  loss_rpn_cls: 0.008428  loss_rpn_loc: 0.1184    time: 0.2446  last_time: 0.1401  data_time: 0.0065  last_data_time: 0.0032   lr: 0.0003033  max_mem: 1562M\n",
            "[02/16 16:58:39 d2.utils.events]:  eta: 0:00:23  iter: 399  total_loss: 0.6836  loss_cls: 0.118  loss_box_reg: 0.2747  loss_mask: 0.1299  loss_rpn_cls: 0.004098  loss_rpn_loc: 0.1215    time: 0.2442  last_time: 0.3076  data_time: 0.0042  last_data_time: 0.0030   lr: 0.00031928  max_mem: 1562M\n",
            "[02/16 16:58:45 d2.utils.events]:  eta: 0:00:19  iter: 419  total_loss: 0.6566  loss_cls: 0.1283  loss_box_reg: 0.2457  loss_mask: 0.1347  loss_rpn_cls: 0.005401  loss_rpn_loc: 0.1318    time: 0.2453  last_time: 0.2545  data_time: 0.0105  last_data_time: 0.0054   lr: 0.00033526  max_mem: 1562M\n",
            "[02/16 16:58:49 d2.utils.events]:  eta: 0:00:14  iter: 439  total_loss: 0.648  loss_cls: 0.1294  loss_box_reg: 0.2439  loss_mask: 0.1371  loss_rpn_cls: 0.004067  loss_rpn_loc: 0.1007    time: 0.2444  last_time: 0.2829  data_time: 0.0040  last_data_time: 0.0059   lr: 0.00035125  max_mem: 1562M\n",
            "[02/16 16:58:54 d2.utils.events]:  eta: 0:00:09  iter: 459  total_loss: 0.5868  loss_cls: 0.1165  loss_box_reg: 0.2245  loss_mask: 0.1239  loss_rpn_cls: 0.004693  loss_rpn_loc: 0.117    time: 0.2435  last_time: 0.2247  data_time: 0.0032  last_data_time: 0.0065   lr: 0.00036723  max_mem: 1562M\n",
            "[02/16 16:58:59 d2.utils.events]:  eta: 0:00:04  iter: 479  total_loss: 0.5936  loss_cls: 0.1184  loss_box_reg: 0.236  loss_mask: 0.123  loss_rpn_cls: 0.005522  loss_rpn_loc: 0.1566    time: 0.2442  last_time: 0.2767  data_time: 0.0075  last_data_time: 0.0032   lr: 0.00038322  max_mem: 1562M\n",
            "[02/16 16:59:04 d2.utils.events]:  eta: 0:00:00  iter: 499  total_loss: 0.6172  loss_cls: 0.1231  loss_box_reg: 0.2313  loss_mask: 0.123  loss_rpn_cls: 0.006212  loss_rpn_loc: 0.1379    time: 0.2436  last_time: 0.2753  data_time: 0.0038  last_data_time: 0.0031   lr: 0.0003992  max_mem: 1562M\n",
            "[02/16 16:59:05 d2.engine.hooks]: Overall training speed: 498 iterations in 0:02:01 (0.2436 s / it)\n",
            "[02/16 16:59:05 d2.engine.hooks]: Total training time: 0:02:08 (0:00:07 on hooks)\n"
          ]
        }
      ],
      "source": [
        "path = \"/content/drive/MyDrive/SI-Org-Chart/data/Org_chart/learning\"\n",
        "path_train = path + \"/train\"\n",
        "path_coco = path + \"/Organization_annotation.json\"\n",
        "path_data = \"/content/drive/MyDrive/SI-Org-Chart/data/Org_chart/cropped\"\n",
        "# set train data\n",
        "register_coco_instances(\"org_chart_train\", {}, path_coco, path_train)\n",
        "\n",
        "# setting for using the model\n",
        "cfg = get_cfg() # initialize\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"org_chart_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 1\n",
        "cfg.SOLVER.BASE_LR = 0.0004\n",
        "cfg.SOLVER.MAX_ITER = (500)\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (128)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n",
        "\n",
        "# train\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True) # for output\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRuY2farKg3r"
      },
      "outputs": [],
      "source": [
        "# the function for making the meta-data dict of the test data\n",
        "def get_test_dicts(img_dir):\n",
        "    img_files = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "    dataset_dicts = []\n",
        "    for idx, img_file in enumerate(img_files):\n",
        "        record = {}\n",
        "        record[\"file_name\"] = img_file\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"], record[\"width\"] = cv2.imread(img_file).shape[:2]\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "\n",
        "# change the test data form for dectron2\n",
        "DatasetCatalog.register(\"orgs\", lambda: get_test_dicts(path_data))\n",
        "MetadataCatalog.get(\"orgs\").set(thing_classes=[\"department\"])\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # load trained weights\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8  # score\n",
        "cfg.DATASETS.TEST = (\"orgs\", )  # set the test data to the model\n",
        "\n",
        "# detect departments\n",
        "predictor = DefaultPredictor(cfg)\n",
        "metadata = MetadataCatalog.get(\"orgs\")\n",
        "dataset_dicts = DatasetCatalog.get(\"orgs\")\n",
        "output_path = \"/content/drive/MyDrive/SI-Org-Chart/data/Org_chart/output\"\n",
        "for d in tqdm(dataset_dicts):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(img)\n",
        "    json_output = {\n",
        "    \"file_name\": d[\"file_name\"],\n",
        "    \"pred_boxes\": outputs[\"instances\"].pred_boxes.tensor.cpu().numpy().tolist(),\n",
        "    \"scores\": outputs[\"instances\"].scores.cpu().numpy().tolist(),\n",
        "    \"pred_classes\": outputs[\"instances\"].pred_classes.cpu().numpy().tolist(),\n",
        "    \"num_department\": len(outputs[\"instances\"].pred_boxes.tensor.cpu().numpy().tolist())\n",
        "    }\n",
        "    # save JSON\n",
        "    base_name = os.path.basename(d[\"file_name\"])\n",
        "    json_name = base_name.replace(\".png\", \".json\")\n",
        "    json_path = os.path.join(output_path, json_name)\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump(json_output, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
